
@article{metropolis_equation_1953,
	title = {Equation of {State} {Calculations} by {Fast} {Computing} {Machines}},
	volume = {21},
	issn = {0021-9606, 1089-7690},
	url = {http://aip.scitation.org/doi/10.1063/1.1699114},
	doi = {10.1063/1.1699114},
	language = {en},
	number = {6},
	urldate = {2023-02-03},
	journal = {The Journal of Chemical Physics},
	author = {Metropolis, Nicholas and Rosenbluth, Arianna W. and Rosenbluth, Marshall N. and Teller, Augusta H. and Teller, Edward},
	month = jun,
	year = {1953},
	pages = {1087--1092},
	file = {Metropolis et al. - 1953 - Equation of State Calculations by Fast Computing M.pdf:/home/dg22309/Zotero/storage/UITYPMXQ/Metropolis et al. - 1953 - Equation of State Calculations by Fast Computing M.pdf:application/pdf},
}

@article{hastings_monte_1970,
	title = {Monte {Carlo} {Sampling} {Methods} {Using} {Markov} {Chains} and {Their} {Applications}},
	abstract = {A generalization of the sampling method introduced by Metropolis et al. (1953) is presented along with an exposition of the relevant theory, techniques of application and methods and difficulties of assessing the error in Monte Carlo estimates. Examples of the methods, including the generation of random orthogonal matrices and potential applications of the methods to numerical problems arising in statistics, are discussed.},
	language = {en},
	author = {Hastings, W K},
	year = {1970},
	file = {Hastings - 2023 - Monte Carlo Sampling Methods Using Markov Chains a.pdf:/home/dg22309/Zotero/storage/F2DEIDLR/Hastings - 2023 - Monte Carlo Sampling Methods Using Markov Chains a.pdf:application/pdf},
}

@article{solonen_efficient_2012,
	title = {Efficient {MCMC} for {Climate} {Model} {Parameter} {Estimation}: {Parallel} {Adaptive} {Chains} and {Early} {Rejection}},
	volume = {7},
	issn = {1936-0975, 1931-6690},
	shorttitle = {Efficient {MCMC} for {Climate} {Model} {Parameter} {Estimation}},
	url = {https://projecteuclid.org/journals/bayesian-analysis/volume-7/issue-3/Efficient-MCMC-for-Climate-Model-Parameter-Estimation--Parallel-Adaptive/10.1214/12-BA724.full},
	doi = {10.1214/12-BA724},
	abstract = {The emergence of Markov chain Monte Carlo (MCMC) methods has opened a way for Bayesian analysis of complex models. Running MCMC samplers typically requires thousands of model evaluations, which can exceed available computer resources when this evaluation is computationally intensive. We will discuss two generally applicable techniques to improve the efficiency of MCMC. First, we consider a parallel version of the adaptive MCMC algorithm of Haario et al. (2001), implementing the idea of inter-chain adaptation introduced by Craiu et al. (2009). Second, we present an early rejection (ER) approach, where model simulation is stopped as soon as one can conclude that the proposed parameter value will be rejected by the MCMC algorithm. This work is motivated by practical needs in estimating parameters of climate and Earth system models. These computationally intensive models involve non-linear expressions of the geophysical and biogeochemical processes of the Earth system. Modeling of these processes, especially those operating in scales smaller than the model grid, involves a number of specified parameters, or ‘tunables’. MCMC methods are applicable for estimation of these parameters, but they are computationally very demanding. Efficient MCMC variants are thus needed to obtain reliable results in reasonable time. Here we evaluate the computational gains attainable through parallel adaptive MCMC and Early Rejection using both simple examples and a realistic climate model.},
	number = {3},
	urldate = {2023-05-04},
	journal = {Bayesian Analysis},
	author = {Solonen, Antti and Ollinaho, Pirkka and Laine, Marko and Haario, Heikki and Tamminen, Johanna and Järvinen, Heikki},
	month = sep,
	year = {2012},
	note = {Publisher: International Society for Bayesian Analysis},
	keywords = {adaptive MCMC, Climate Models, Early Rejection, Parallel MCMC},
	pages = {715--736},
	file = {Full Text PDF:/home/dg22309/Zotero/storage/HBX8ET9T/Solonen et al. - 2012 - Efficient MCMC for Climate Model Parameter Estimat.pdf:application/pdf},
}

@article{homan_no-u-turn_2014,
	title = {The {No}-{U}-{Turn} {Sampler}: {Adaptively} {Setting} {Path} {Lengths} in {Hamiltonian} {Monte} {Carlo}},
	abstract = {Hamiltonian Monte Carlo (HMC) is a Markov chain Monte Carlo (MCMC) algorithm that avoids the random walk behavior and sensitivity to correlated parameters that plague many MCMC methods by taking a series of steps informed by ﬁrst-order gradient information. These features allow it to converge to high-dimensional target distributions much more quickly than simpler methods such as random walk Metropolis or Gibbs sampling. However, HMC’s performance is highly sensitive to two user-speciﬁed parameters: a step size and a desired number of steps L. In particular, if L is too small then the algorithm exhibits undesirable random walk behavior, while if L is too large the algorithm wastes computation. We introduce the No-U-Turn Sampler (NUTS), an extension to HMC that eliminates the need to set a number of steps L. NUTS uses a recursive algorithm to build a set of likely candidate points that spans a wide swath of the target distribution, stopping automatically when it starts to double back and retrace its steps. Empirically, NUTS performs at least as eﬃciently as (and sometimes more eﬃciently than) a well tuned standard HMC method, without requiring user intervention or costly tuning runs. We also derive a method for adapting the step size parameter on the ﬂy based on primal-dual averaging. NUTS can thus be used with no hand-tuning at all, making it suitable for applications such as BUGS-style automatic inference engines that require eﬃcient “turnkey” samplers.},
	language = {en},
	author = {Hoﬀman, Matthew D and Gelman, Andrew},
	month = apr,
	year = {2014},
	file = {Hoﬀman and Gelman - The No-U-Turn Sampler Adaptively Setting Path Len.pdf:/home/dg22309/Zotero/storage/SDRXWDY7/Hoﬀman and Gelman - The No-U-Turn Sampler Adaptively Setting Path Len.pdf:application/pdf},
}

@misc{roberts_introduction_2011,
	title = {An introduction to adaptive {MCMC}},
	url = {https://warwick.ac.uk/fac/sci/maths/research/miraw/days/montecarlo/abstracts/adaptivemiraw11_roberts.pdf},
	language = {en},
	author = {Roberts, Gareth},
	month = mar,
	year = {2011},
	file = {Roberts - An introduction to adaptive MCMC.pdf:/home/dg22309/Zotero/storage/CVP4HJXX/Roberts - An introduction to adaptive MCMC.pdf:application/pdf},
}

@article{haario_adaptive_2001,
	title = {An {Adaptive} {Metropolis} {Algorithm}},
	volume = {7},
	issn = {1350-7265},
	url = {https://www.jstor.org/stable/3318737},
	doi = {10.2307/3318737},
	abstract = {A proper choice of a proposal distribution for Markov chain Monte Carlo methods, for example for the Metropolis-Hastings algorithm, is well known to be a crucial factor for the convergence of the algorithm. In this paper we introduce an adaptive Metropolis (AM) algorithm, where the Gaussian proposal distribution is updated along the process using the full information cumulated so far. Due to the adaptive nature of the process, the AM algorithm is non-Markovian, but we establish here that it has the correct ergodic properties. We also include the results of our numerical tests, which indicate that the AM algorithm competes well with traditional Metropolis-Hastings algorithms, and demonstrate that the AM algorithm is easy to use in practical computation.},
	number = {2},
	urldate = {2023-06-15},
	journal = {Bernoulli},
	author = {Haario, Heikki and Saksman, Eero and Tamminen, Johanna},
	year = {2001},
	note = {Publisher: International Statistical Institute (ISI) and Bernoulli Society for Mathematical Statistics and Probability},
	pages = {223--242},
	file = {JSTOR Full Text PDF:/home/dg22309/Zotero/storage/8DQAJ8H7/Haario et al. - 2001 - An Adaptive Metropolis Algorithm.pdf:application/pdf},
}

@article{atchade_adaptive_2006,
	title = {An {Adaptive} {Version} for the {Metropolis} {Adjusted} {Langevin} {Algorithm} with a {Truncated} {Drift}},
	volume = {8},
	issn = {1387-5841, 1573-7713},
	url = {http://link.springer.com/10.1007/s11009-006-8550-0},
	doi = {10.1007/s11009-006-8550-0},
	abstract = {This paper proposes an adaptive version for the Metropolis adjusted Langevin algorithm with a truncated drift (T-MALA). The scale parameter and the covariance matrix of the proposal kernel of the algorithm are simultaneously and recursively updated in order to reach the optimal acceptance rate of 0.574 (see Roberts and Rosenthal (2001)) and to estimate and use the correlation structure of the target distribution. We develop some convergence results for the algorithm. A simulation example is presented.},
	language = {en},
	number = {2},
	urldate = {2023-06-15},
	journal = {Methodology and Computing in Applied Probability},
	author = {Atchadé, Yves F.},
	month = jun,
	year = {2006},
	pages = {235--254},
	file = {Atchadé - 2006 - An Adaptive Version for the Metropolis Adjusted La.pdf:/home/dg22309/Zotero/storage/9EYIRBGM/Atchadé - 2006 - An Adaptive Version for the Metropolis Adjusted La.pdf:application/pdf},
}

@article{atchade_wang-landau_nodate,
	title = {{THE} {WANG}-{LANDAU} {ALGORITHM} {IN} {GENERAL} {STATE} {SPACES}: {APPLICATIONS} {AND} {CONVERGENCE} {ANALYSIS}},
	abstract = {The Wang-Landau algorithm (Wang and Landau (2001)) is a recent Monte Carlo method that has generated much interest in the Physics literature due to some spectacular simulation performances. The objective of this paper is two-fold. First, we show that the algorithm can be naturally extended to more general state spaces and used to improve on Markov Chain Monte Carlo schemes of more interest in Statistics. In a second part, we study asymptotic behaviors of the algorithm. We show that with an appropriate choice of the step-size, the algorithm is consistent and a strong law of large numbers holds under some fairly mild conditions. We have also shown by simulations the potential advantage of the WL algorithm for problems in Bayesian inference.},
	language = {en},
	author = {Atchade, Yves F and Liu, Jun S},
	file = {Atchade and Liu - THE WANG-LANDAU ALGORITHM IN GENERAL STATE SPACES.pdf:/home/dg22309/Zotero/storage/CFY6X6DT/Atchade and Liu - THE WANG-LANDAU ALGORITHM IN GENERAL STATE SPACES.pdf:application/pdf},
}

@article{takaishi_bayesian_2010,
	title = {Bayesian inference with an adaptive proposal density for {GARCH} models},
	volume = {221},
	issn = {1742-6596},
	url = {https://iopscience.iop.org/article/10.1088/1742-6596/221/1/012011},
	doi = {10.1088/1742-6596/221/1/012011},
	abstract = {We perform the Bayesian inference of a GARCH model by the Metropolis-Hastings algorithm with an adaptive proposal density. The adaptive proposal density is assumed to be the Student’s t-distribution and the distribution parameters are evaluated by using the data sampled during the simulation. We apply the method for the QGARCH model which is one of asymmetric GARCH models and make empirical studies for Nikkei 225, DAX and Hang indexes. We ﬁnd that autocorrelation times from our method are very small, thus the method is very eﬃcient for generating uncorrelated Monte Carlo data. The results from the QGARCH model show that all the three indexes show the leverage eﬀect, i.e. the volatility is high after negative observations.},
	language = {en},
	urldate = {2023-06-15},
	journal = {Journal of Physics: Conference Series},
	author = {Takaishi, Tetsuya},
	month = apr,
	year = {2010},
	pages = {012011},
	file = {Takaishi - 2010 - Bayesian inference with an adaptive proposal densi.pdf:/home/dg22309/Zotero/storage/Y3R87DQQ/Takaishi - 2010 - Bayesian inference with an adaptive proposal densi.pdf:application/pdf},
}

@article{andrieu_tutorial_2008,
	title = {A tutorial on adaptive {MCMC}},
	volume = {18},
	issn = {0960-3174, 1573-1375},
	url = {http://link.springer.com/10.1007/s11222-008-9110-y},
	doi = {10.1007/s11222-008-9110-y},
	abstract = {We review adaptive Markov chain Monte Carlo algorithms (MCMC) as a mean to optimise their performance. Using simple toy examples we review their theoretical underpinnings, and in particular show why adaptive MCMC algorithms might fail when some fundamental properties are not satisﬁed. This leads to guidelines concerning the design of correct algorithms. We then review criteria and the useful framework of stochastic approximation, which allows one to systematically optimise generally used criteria, but also analyse the properties of adaptive MCMC algorithms. We then propose a series of novel adaptive algorithms which prove to be robust and reliable in practice. These algorithms are applied to artiﬁcial and high dimensional scenarios, but also to the classic mine disaster dataset inference problem.},
	language = {en},
	number = {4},
	urldate = {2023-06-15},
	journal = {Statistics and Computing},
	author = {Andrieu, Christophe and Thoms, Johannes},
	month = dec,
	year = {2008},
	pages = {343--373},
	file = {Andrieu and Thoms - 2008 - A tutorial on adaptive MCMC.pdf:/home/dg22309/Zotero/storage/63MZD37A/Andrieu and Thoms - 2008 - A tutorial on adaptive MCMC.pdf:application/pdf},
}

@article{grenander_representations_1994,
	title = {Representations of {Knowledge} in {Complex} {Systems}},
	volume = {56},
	issn = {0035-9246},
	url = {https://www.jstor.org/stable/2346184},
	abstract = {Modern sensor technologies, especially in biomedicine, produce increasingly detailed and informative image ensembles, many extremely complex. It will be argued that pattern theory can supply mathematical representations of subject-matter knowledge that can be used as a basis for algorithmic `understanding' of such pictures. After a brief survey of the basic principles of pattern theory we shall illustrate them by an application to a concrete situation: high magnification (greater than 15 000 ×) electron micrographs of cardiac muscle cells. The aim is to build algorithms for automatic hypothesis formation concerning the number, location, orientation and shape of mitochondria and membranes. For this we construct a pattern theoretic model in the form of a prior probability measure on the space of configurations describing these hypotheses. This measure is synthesized by solving sequentially a jump-diffusion equation of generalized Langevin form. The jumps occur for the creation-annihilation of hypotheses, corresponding to a jump from one continuum to another in configuration (hypothesis) space. These continua (subhypotheses) are expressed in terms of products of low dimensional Lie groups acting on the generators of a template. We use a modified Bayes approach to obtain the hypothesis formation, also organized by solving a generalized Langevin equation. To justify this it is shown that the resulting jump-diffusion process is ergodic so that the solution converges to the desired probability measure. To speed up the convergence we reduce the computation of the drift term in the stochastic differential equation analytically to a curvilinear integral, with the random term computed almost instantaneously. The algorithms thus obtained are implemented, both for mitochondria and membranes, on a 4000 processor parallel machine. Photographs of the graphics illustrate how automatic hypothesis formation is achieved. This approach is applied to deformable neuroanatomical atlases and tracking recognition from narrow band and high resolution sensor arrays.},
	number = {4},
	urldate = {2023-06-15},
	journal = {Journal of the Royal Statistical Society. Series B (Methodological)},
	author = {Grenander, Ulf and Miller, Michael I.},
	year = {1994},
	note = {Publisher: [Royal Statistical Society, Wiley]},
	pages = {549--603},
	file = {JSTOR Full Text PDF:/home/dg22309/Zotero/storage/GLCDZLGD/Grenander and Miller - 1994 - Representations of Knowledge in Complex Systems.pdf:application/pdf},
}

@article{rossky_brownian_2008,
	title = {Brownian dynamics as smart {Monte} {Carlo} simulation},
	volume = {69},
	issn = {0021-9606},
	url = {https://doi.org/10.1063/1.436415},
	doi = {10.1063/1.436415},
	abstract = {A new Monte Carlo simulation procedure is developed which is expected to produce more rapid convergence than the standard Metropolis method. The trial particle moves are chosen in accord with a Brownian dynamics algorithm rather than at random. For two model systems, a string of point masses joined by harmonic springs and a cluster of charged soft spheres, the new procedure is compared to the standard one and shown to manifest a more rapid convergence rate for some important energetic and structural properties.},
	number = {10},
	urldate = {2023-06-15},
	journal = {The Journal of Chemical Physics},
	author = {Rossky, P. J. and Doll, J. D. and Friedman, H. L.},
	month = aug,
	year = {2008},
	pages = {4628--4633},
	file = {Full Text PDF:/home/dg22309/Zotero/storage/ZJXBGJGT/Rossky et al. - 2008 - Brownian dynamics as smart Monte Carlo simulation.pdf:application/pdf;Snapshot:/home/dg22309/Zotero/storage/45ZXVSNV/Brownian-dynamics-as-smart-Monte-Carlo-simulation.html:text/html},
}

@article{gilks_adaptive_1998,
	title = {Adaptive {Markov} {Chain} {Monte} {Carlo} through {Regeneration}},
	volume = {93},
	issn = {0162-1459},
	url = {https://www.jstor.org/stable/2669848},
	doi = {10.2307/2669848},
	abstract = {Markov chain Monte Carlo (MCMC) is used for evaluating expectations of functions of interest under a target distribution π. This is done by calculating averages over the sample path of a Markov chain having π as its stationary distribution. For computational efficiency, the Markov chain should be rapidly mixing. This sometimes can be achieved only by careful design of the transition kernel of the chain, on the basis of a detailed preliminary exploratory analysis of π. An alternative approach might be to allow the transition kernel to adapt whenever new features of π are encountered during the MCMC run. However, if such adaptation occurs infinitely often, then the stationary distribution of the chain may be disturbed. We describe a framework, based on the concept of Markov chain regeneration, which allows adaptation to occur infinitely often but does not disturb the stationary distribution of the chain or the consistency of sample path averages.},
	number = {443},
	urldate = {2023-06-15},
	journal = {Journal of the American Statistical Association},
	author = {Gilks, Walter R. and Roberts, Gareth O. and Sahu, Sujit K.},
	year = {1998},
	note = {Publisher: [American Statistical Association, Taylor \& Francis, Ltd.]},
	pages = {1045--1054},
	file = {JSTOR Full Text PDF:/home/dg22309/Zotero/storage/M3SCFPPZ/Gilks et al. - 1998 - Adaptive Markov Chain Monte Carlo through Regenera.pdf:application/pdf},
}

@article{andrieu_ergodicity_2006,
	title = {On the ergodicity properties of some adaptive {MCMC} algorithms},
	volume = {16},
	issn = {1050-5164, 2168-8737},
	url = {https://projecteuclid.org/journals/annals-of-applied-probability/volume-16/issue-3/On-the-ergodicity-properties-of-some-adaptive-MCMC-algorithms/10.1214/105051606000000286.full},
	doi = {10.1214/105051606000000286},
	abstract = {In this paper we study the ergodicity properties of some adaptive Markov chain Monte Carlo algorithms (MCMC) that have been recently proposed in the literature. We prove that under a set of verifiable conditions, ergodic averages calculated from the output of a so-called adaptive MCMC sampler converge to the required value and can even, under more stringent assumptions, satisfy a central limit theorem. We prove that the conditions required are satisfied for the independent Metropolis–Hastings algorithm and the random walk Metropolis algorithm with symmetric increments. Finally, we propose an application of these results to the case where the proposal distribution of the Metropolis–Hastings update is a mixture of distributions from a curved exponential family.},
	number = {3},
	urldate = {2023-06-15},
	journal = {The Annals of Applied Probability},
	author = {Andrieu, Christophe and Moulines, Éric},
	month = aug,
	year = {2006},
	note = {Publisher: Institute of Mathematical Statistics},
	keywords = {Adaptive Markov chain Monte Carlo, 65C05, 60J27, 60J35, 65C40, 93E35, martingale, Metropolis–Hastings algorithm, Poisson method, randomly varying truncation, self-tuning algorithm, state-dependent noise, stochastic approximation},
	pages = {1462--1505},
	file = {Full Text PDF:/home/dg22309/Zotero/storage/BWBEWVNF/Andrieu and Moulines - 2006 - On the ergodicity properties of some adaptive MCMC.pdf:application/pdf},
}

@article{roberts_coupling_2005,
	title = {Coupling and {Ergodicity} of {Adaptive} {MCMC}},
	abstract = {We consider basic ergodicity properties of adaptive MCMC algorithms under minimal assumptions, using coupling constructions. We prove convergence in distribution and a weak law of large numbers. We also give counter-examples to demonstrate that the assumptions we make are not redundant.},
	language = {en},
	author = {Roberts, Gareth O and Rosenthal, Jeﬀrey S},
	month = mar,
	year = {2005},
	file = {Roberts and Rosenthal - Coupling and Ergodicity of Adaptive MCMC.pdf:/home/dg22309/Zotero/storage/9DYGY53Q/Roberts and Rosenthal - Coupling and Ergodicity of Adaptive MCMC.pdf:application/pdf},
}

@article{atchade_limit_2010,
	title = {Limit theorems for some adaptive {MCMC} algorithms with subgeometric kernels},
	volume = {16},
	issn = {1350-7265},
	url = {https://www.jstor.org/stable/20680214},
	abstract = {This paper deals with the ergodicity (convergence of the marginals) and the law of large numbers for adaptive MCMC algorithms built from transition kernels that are not necessarily geometrically ergodic. We develop a number of results that significantly broaden the class of adaptive MCMC algorithms for which rigorous analysis is now possible. As an example, we give a detailed analysis of the adaptive Metropolis algorithm of Haario et al. [Bernoulli 7 (2001) 223-242] when the target distribution is subexponential in the tails.},
	number = {1},
	urldate = {2023-06-15},
	journal = {Bernoulli},
	author = {Atchadé, Yves and Fort, Gersende},
	year = {2010},
	note = {Publisher: [Bernoulli Society for Mathematical Statistics and Probability, International Statistical Institute (ISI)]},
	pages = {116--154},
	file = {JSTOR Full Text PDF:/home/dg22309/Zotero/storage/NPS6ZA79/Atchadé and Fort - 2010 - Limit theorems for some adaptive MCMC algorithms w.pdf:application/pdf},
}

@article{roberts_optimal_2001,
	title = {Optimal {Scaling} for {Various} {Metropolis}-{Hastings} {Algorithms}},
	volume = {16},
	issn = {0883-4237},
	url = {https://www.jstor.org/stable/3182776},
	abstract = {We review and extend results related to optimal scaling of Metropolis-Hastings algorithms. We present various theoretical results for the high-dimensional limit. We also present simulation studies which confirm the theoretical results in finite-dimensional contexts.},
	number = {4},
	urldate = {2023-07-03},
	journal = {Statistical Science},
	author = {Roberts, Gareth O. and Rosenthal, Jeffrey S.},
	year = {2001},
	note = {Publisher: Institute of Mathematical Statistics},
	pages = {351--367},
	file = {JSTOR Full Text PDF:/home/dg22309/Zotero/storage/I5DUU2GH/Roberts and Rosenthal - 2001 - Optimal Scaling for Various Metropolis-Hastings Al.pdf:application/pdf},
}

@phdthesis{yang_ergodicity_2008,
	title = {Ergodicity of {Adaptive} {MCMC} and its {Applications}},
	url = {http://probability.ca/jeff/ftpdir/chaothesis.pdf},
	language = {en},
	school = {University of Toronto},
	author = {Yang, Chao},
	year = {2008},
	file = {Yang - Ergodicity of Adaptive MCMC and its Applications.pdf:/home/dg22309/Zotero/storage/QKIXYJYR/Yang - Ergodicity of Adaptive MCMC and its Applications.pdf:application/pdf},
}

@incollection{gelman_efficient_1996,
	title = {Efficient {Metropolis} jumping rules},
	booktitle = {Bayesian {Statistics}},
	publisher = {Oxford University Press, Oxford},
	author = {Gelman, A. and Roberts, G. O. and Gilks, W. R.},
	editor = {Bernardo, J. M. and Berger, J. O. and Dawid, A. P. and Smith, A. F. M.},
	year = {1996},
	pages = {599--608},
	file = {baystat5.pdf:/home/dg22309/Zotero/storage/SBDR4B9S/baystat5.pdf:application/pdf},
}

@article{roberts_geometric_1996,
	title = {Geometric convergence and central limit theorems for multidimensional {Hastings} and {Metropolis} algorithms},
	volume = {83},
	issn = {0006-3444},
	url = {https://doi.org/10.1093/biomet/83.1.95},
	doi = {10.1093/biomet/83.1.95},
	abstract = {We develop results on geometric ergodicity of Markov chains and apply these and other recent results in Markov chain theory to multidimensional Hastings and Metropolis algorithms. For those based on random walk candidate distributions, we find sufficient conditions for moments and moment generating functions to converge at a geometric rate to a prescribed distribution π. By phrasing the conditions in terms of the curvature of the densities we show that the results apply to all distributions with positive densities in a large class which encompasses many commonly-used statistical forms. From these results we develop central limit theorems for the Metropolis algorithm. Converse results, showing non-geometric convergence rates for chains where the rejection rate is not bounded away from unity, are also given; these show that the negative-definiteness property is not redundant.},
	number = {1},
	urldate = {2023-07-03},
	journal = {Biometrika},
	author = {Roberts, G. O. and Tweedie, R. L.},
	month = mar,
	year = {1996},
	pages = {95--110},
	file = {Full Text PDF:/home/dg22309/Zotero/storage/487UGRBP/ROBERTS and TWEEDIE - 1996 - Geometric convergence and central limit theorems f.pdf:application/pdf;Snapshot:/home/dg22309/Zotero/storage/BR9HLUFW/255487.html:text/html},
}

@article{delyon_accelerated_1993,
	title = {Accelerated {Stochastic} {Approximation}},
	volume = {3},
	issn = {1052-6234},
	url = {https://epubs.siam.org/doi/10.1137/0803045},
	doi = {10.1137/0803045},
	abstract = {A new recursive algorithm of stochastic approximation type with the averaging of trajectories is investigated. Convergence with probability one is proved for a variety of classical optimization and identification problems. It is also demonstrated for these problems that the proposed algorithm achieves the highest possible rate of convergence.},
	number = {4},
	urldate = {2023-07-04},
	journal = {SIAM Journal on Optimization},
	author = {Delyon, Bernard and Juditsky, Anatoli},
	month = nov,
	year = {1993},
	note = {Publisher: Society for Industrial and Applied Mathematics},
	pages = {868--881},
	file = {Full Text PDF:/home/dg22309/Zotero/storage/DG34W6IQ/Delyon and Juditsky - 1993 - Accelerated Stochastic Approximation.pdf:application/pdf},
}

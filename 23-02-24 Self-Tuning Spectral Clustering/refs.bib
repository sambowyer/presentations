
@misc{giordano_casey_r_nodate,
	title = {R: {Iterated} {Principal} {Axis} {Factor} {Analysis} (fapa)},
	url = {https://search.r-project.org/CRAN/refmans/fungible/html/fapa.html},
	urldate = {2023-02-02},
	author = {{Giordano, Casey} and {Waller, Niels}},
	file = {R\: Iterated Principal Axis Factor Analysis (fapa):/home/dg22309/Zotero/storage/5U4G9CLF/fapa.html:text/html},
}

@misc{noauthor_icamusical_nodate,
	title = {icamusical},
	url = {https://www.kaggle.com/datasets/chittalpatel/icamusical},
	abstract = {Kaggle is the world’s largest data science community with powerful tools and resources to help you achieve your data science goals.},
	language = {en},
	urldate = {2023-02-03},
	file = {Snapshot:/home/dg22309/Zotero/storage/UZE4K3NX/icamusical.html:text/html},
}

@article{zelnik-manor_self-tuning_2004,
	title = {Self-{Tuning} {Spectral} {Clustering}},
	abstract = {We study a number of open issues in spectral clustering: (i) Selecting the appropriate scale of analysis, (ii) Handling multi-scale data, (iii) Clustering with irregular background clutter, and, (iv) Finding automatically the number of groups. We ﬁrst propose that a ‘local’ scale should be used to compute the afﬁnity between each pair of points. This local scaling leads to better clustering especially when the data includes multiple scales and when the clusters are placed within a cluttered background. We further suggest exploiting the structure of the eigenvectors to infer automatically the number of groups. This leads to a new algorithm in which the ﬁnal randomly initialized k-means stage is eliminated.},
	language = {en},
	author = {Zelnik-Manor, Lihi and Perona, Pietro},
	year = {2004},
	file = {Zelnik-manor and Perona - Self-Tuning Spectral Clustering.pdf:/home/dg22309/Zotero/storage/T3VD57LQ/Zelnik-manor and Perona - Self-Tuning Spectral Clustering.pdf:application/pdf},
}

@article{ng_spectral_2001,
	title = {On {Spectral} {Clustering}: {Analysis} and an algorithm},
	abstract = {Despite many empirical successes of spectral clustering methodsalgorithms that cluster points using eigenvectors of matrices derived from the data- there are several unresolved issues. First, there are a wide variety of algorithms that use the eigenvectors in slightly different ways. Second, many of these algorithms have no proof that they will actually compute a reasonable clustering. In this paper, we present a simple spectral clustering algorithm that can be implemented using a few lines of Matlab. Using tools from matrix perturbation theory, we analyze the algorithm, and give conditions under which it can be expected to do well. We also show surprisingly good experimental results on a number of challenging clustering problems.},
	language = {en},
	author = {Ng, Andrew Y and Jordan, Michael I and Weiss, Yair},
	year = {2001},
	file = {Ng et al. - On Spectral Clustering Analysis and an algorithm.pdf:/home/dg22309/Zotero/storage/L3LJRP2J/Ng et al. - On Spectral Clustering Analysis and an algorithm.pdf:application/pdf},
}

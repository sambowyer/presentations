annotation-target:: https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf

>%%
>```annotation-json
>{"created":"2023-08-06T13:36:35.779Z","updated":"2023-08-06T13:36:35.779Z","document":{"title":"lievin23a.pdf","link":[{"href":"urn:x-pdf:ed2b119e8f77e065d14f1357b2c13c63"},{"href":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf"}],"documentFingerprint":"ed2b119e8f77e065d14f1357b2c13c63"},"uri":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf","target":[{"source":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf","selector":[{"type":"TextPositionSelector","start":376,"end":507},{"type":"TextQuoteSelector","exact":"end-to-end training and evaluation ofretrieval-augmented models, focusing on open-domain question answering and language mod-elling","prefix":"pen-Domain (VOD) frame-work for ","suffix":". The VOD objective, a self-norm"}]}]}
>```
>%%
>*%%PREFIX%%pen-Domain (VOD) frame-work for%%HIGHLIGHT%% ==end-to-end training and evaluation ofretrieval-augmented models, focusing on open-domain question answering and language mod-elling== %%POSTFIX%%. The VOD objective, a self-norm*
>%%LINK%%[[#^kpdmfddrdmg|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^kpdmfddrdmg


>%%
>```annotation-json
>{"created":"2023-08-06T13:38:15.952Z","updated":"2023-08-06T13:38:15.952Z","document":{"title":"lievin23a.pdf","link":[{"href":"urn:x-pdf:ed2b119e8f77e065d14f1357b2c13c63"},{"href":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf"}],"documentFingerprint":"ed2b119e8f77e065d14f1357b2c13c63"},"uri":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf","target":[{"source":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf","selector":[{"type":"TextPositionSelector","start":2125,"end":2293},{"type":"TextQuoteSelector","exact":"arge language models (LLMs) may reacha plateau in their performance due to the limitations of theimplicit knowledge they possess, being incomplete, flawedor out-of-date","prefix":"e) on MedMCQA.tasks.1 However, l","suffix":". Open-domain question answering"}]}]}
>```
>%%
>*%%PREFIX%%e) on MedMCQA.tasks.1 However, l%%HIGHLIGHT%% ==arge language models (LLMs) may reacha plateau in their performance due to the limitations of theimplicit knowledge they possess, being incomplete, flawedor out-of-date== %%POSTFIX%%. Open-domain question answering*
>%%LINK%%[[#^de7918samt|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^de7918samt


>%%
>```annotation-json
>{"created":"2023-08-06T13:38:27.183Z","text":"big\n","updated":"2023-08-06T13:38:27.183Z","document":{"title":"lievin23a.pdf","link":[{"href":"urn:x-pdf:ed2b119e8f77e065d14f1357b2c13c63"},{"href":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf"}],"documentFingerprint":"ed2b119e8f77e065d14f1357b2c13c63"},"uri":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf","target":[{"source":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf","selector":[{"type":"TextPositionSelector","start":2295,"end":2422},{"type":"TextQuoteSelector","exact":"Open-domain question answering (ODQA)consists of augmenting LMs with external knowledge basesindexed with a retrieval mechanism","prefix":"complete, flawedor out-of-date. ","suffix":". This approach waspopularized i"}]}]}
>```
>%%
>*%%PREFIX%%complete, flawedor out-of-date.%%HIGHLIGHT%% ==Open-domain question answering (ODQA)consists of augmenting LMs with external knowledge basesindexed with a retrieval mechanism== %%POSTFIX%%. This approach waspopularized i*
>%%LINK%%[[#^s2p86g3vxxk|show annotation]]
>%%COMMENT%%
>big
>
>%%TAGS%%
>
^s2p86g3vxxk


>%%
>```annotation-json
>{"created":"2023-08-06T13:44:29.775Z","updated":"2023-08-06T13:44:29.775Z","document":{"title":"lievin23a.pdf","link":[{"href":"urn:x-pdf:ed2b119e8f77e065d14f1357b2c13c63"},{"href":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf"}],"documentFingerprint":"ed2b119e8f77e065d14f1357b2c13c63"},"uri":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf","target":[{"source":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf","selector":[{"type":"TextPositionSelector","start":4071,"end":4298},{"type":"TextQuoteSelector","exact":"The proposed framework is versatile and applies to vari-ous settings, including extractive, generative, and multiple-choice models for open-domain question answering, as wellas the training of retrieval-enhanced language models","prefix":"g from an approximate posterior.","suffix":".To demonstrate the effectivenes"}]}]}
>```
>%%
>*%%PREFIX%%g from an approximate posterior.%%HIGHLIGHT%% ==The proposed framework is versatile and applies to vari-ous settings, including extractive, generative, and multiple-choice models for open-domain question answering, as wellas the training of retrieval-enhanced language models== %%POSTFIX%%.To demonstrate the effectivenes*
>%%LINK%%[[#^s1cix8kv7z|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^s1cix8kv7z


>%%
>```annotation-json
>{"created":"2023-08-06T13:46:20.932Z","text":"important to have on a slide","updated":"2023-08-06T13:46:20.932Z","document":{"title":"lievin23a.pdf","link":[{"href":"urn:x-pdf:ed2b119e8f77e065d14f1357b2c13c63"},{"href":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf"}],"documentFingerprint":"ed2b119e8f77e065d14f1357b2c13c63"},"uri":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf","target":[{"source":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf","selector":[{"type":"TextPositionSelector","start":5613,"end":5710},{"type":"TextQuoteSelector","exact":"pθ(a,d|q) := pθ(a|d,q)pθ(d|q) parameterized by θ:pθ(a|q) := ∑d∈Dpθ(a|d,q)︸ ︷︷ ︸readerpθ(d|q)︸ ︷︷ ","prefix":"od with a reader-retriever model","suffix":"︸retriever. (1)Variational infer"}]}]}
>```
>%%
>*%%PREFIX%%od with a reader-retriever model%%HIGHLIGHT%% ==pθ(a,d|q) := pθ(a|d,q)pθ(d|q) parameterized by θ:pθ(a|q) := ∑d∈Dpθ(a|d,q)︸ ︷︷ ︸readerpθ(d|q)︸ ︷︷== %%POSTFIX%%︸retriever. (1)Variational infer*
>%%LINK%%[[#^ih3gn6w6w6|show annotation]]
>%%COMMENT%%
>important to have on a slide
>%%TAGS%%
>
^ih3gn6w6w6


>%%
>```annotation-json
>{"created":"2023-08-06T13:46:44.927Z","updated":"2023-08-06T13:46:44.927Z","document":{"title":"lievin23a.pdf","link":[{"href":"urn:x-pdf:ed2b119e8f77e065d14f1357b2c13c63"},{"href":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf"}],"documentFingerprint":"ed2b119e8f77e065d14f1357b2c13c63"},"uri":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf","target":[{"source":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf","selector":[{"type":"TextPositionSelector","start":6343,"end":6394},{"type":"TextQuoteSelector","exact":"LELBO(a,q) := log pθ(a,q) −DKL (rφ(d|a,q)∥pθ(d|a,q)","prefix":" inference can aid likelihood-3 ","suffix":")based learning, ii) The VOD obj"}]}]}
>```
>%%
>*%%PREFIX%%inference can aid likelihood-3%%HIGHLIGHT%% ==LELBO(a,q) := log pθ(a,q) −DKL (rφ(d|a,q)∥pθ(d|a,q)== %%POSTFIX%%)based learning, ii) The VOD obj*
>%%LINK%%[[#^f9awe2ul8k8|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^f9awe2ul8k8


>%%
>```annotation-json
>{"created":"2023-08-06T13:46:56.610Z","text":"include the footnote obv\n","updated":"2023-08-06T13:46:56.610Z","document":{"title":"lievin23a.pdf","link":[{"href":"urn:x-pdf:ed2b119e8f77e065d14f1357b2c13c63"},{"href":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf"}],"documentFingerprint":"ed2b119e8f77e065d14f1357b2c13c63"},"uri":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf","target":[{"source":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf","selector":[{"type":"TextPositionSelector","start":5914,"end":6018},{"type":"TextQuoteSelector","exact":" rφ(d|a,q). This consists of evalu-ating the evidence lower bound (ELBO), a log-likelihoodlower bound.3 ","prefix":"awn froman approximate posterior","suffix":"In open-domain applications, the"}]}]}
>```
>%%
>*%%PREFIX%%awn froman approximate posterior%%HIGHLIGHT%% ==rφ(d|a,q). This consists of evalu-ating the evidence lower bound (ELBO), a log-likelihoodlower bound.3== %%POSTFIX%%In open-domain applications, the*
>%%LINK%%[[#^jmv58pw9c7r|show annotation]]
>%%COMMENT%%
>include the footnote obv
>
>%%TAGS%%
>
^jmv58pw9c7r



>%%
>```annotation-json
>{"created":"2023-08-06T13:53:47.304Z","updated":"2023-08-06T13:53:47.304Z","document":{"title":"lievin23a.pdf","link":[{"href":"urn:x-pdf:ed2b119e8f77e065d14f1357b2c13c63"},{"href":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf"}],"documentFingerprint":"ed2b119e8f77e065d14f1357b2c13c63"},"uri":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf","target":[{"source":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf","selector":[{"type":"TextPositionSelector","start":7415,"end":7555},{"type":"TextQuoteSelector","exact":"ariational Rényi bound (RVB)defined asLα(a,q) := 11 −α log Erφ(d|a,q)[w1−αθ,φ (a,q,d)](2)RVB is a lower bound of the marginal log-likelihood","prefix":"d) :=pθ(a,d|q)r−1φ (d|a,q) the v","suffix":" forα ≥ 0 and is extended by con"}]}]}
>```
>%%
>*%%PREFIX%%d) :=pθ(a,d|q)r−1φ (d|a,q) the v%%HIGHLIGHT%% ==ariational Rényi bound (RVB)defined asLα(a,q) := 11 −α log Erφ(d|a,q)[w1−αθ,φ (a,q,d)](2)RVB is a lower bound of the marginal log-likelihood== %%POSTFIX%%forα ≥ 0 and is extended by con*
>%%LINK%%[[#^j6uicsyzaz|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^j6uicsyzaz


>%%
>```annotation-json
>{"created":"2023-08-06T13:54:10.103Z","updated":"2023-08-06T13:54:10.103Z","document":{"title":"lievin23a.pdf","link":[{"href":"urn:x-pdf:ed2b119e8f77e065d14f1357b2c13c63"},{"href":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf"}],"documentFingerprint":"ed2b119e8f77e065d14f1357b2c13c63"},"uri":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf","target":[{"source":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf","selector":[{"type":"TextPositionSelector","start":7676,"end":7756},{"type":"TextQuoteSelector","exact":"RVB and its gradients can be estimated us-ing K documents sampled from rφ(d|a,q)","prefix":"quals the ELBO.In practice, the ","suffix":". The resultingimportance sampli"}]}]}
>```
>%%
>*%%PREFIX%%quals the ELBO.In practice, the%%HIGHLIGHT%% ==RVB and its gradients can be estimated us-ing K documents sampled from rφ(d|a,q)== %%POSTFIX%%. The resultingimportance sampli*
>%%LINK%%[[#^x45zx9amzwe|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^x45zx9amzwe


>%%
>```annotation-json
>{"created":"2023-08-06T13:55:06.743Z","updated":"2023-08-06T13:55:06.743Z","document":{"title":"lievin23a.pdf","link":[{"href":"urn:x-pdf:ed2b119e8f77e065d14f1357b2c13c63"},{"href":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf"}],"documentFingerprint":"ed2b119e8f77e065d14f1357b2c13c63"},"uri":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf","target":[{"source":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf","selector":[{"type":"TextPositionSelector","start":8148,"end":8235},{"type":"TextQuoteSelector","exact":"Lα=0(a,q) = log pθ(a|q) Lα→1(a,q) =LELBO(a,q)Lα≥0(a,q) ≤log pθ(a|q) LKα (a,q) ≤Lα(a,q) ","prefix":"e RVB and the IW-RVB are (α ≥0):","suffix":".RVB gradient The gradient of th"}]}]}
>```
>%%
>*%%PREFIX%%e RVB and the IW-RVB are (α ≥0):%%HIGHLIGHT%% ==Lα=0(a,q) = log pθ(a|q) Lα→1(a,q) =LELBO(a,q)Lα≥0(a,q) ≤log pθ(a|q) LKα (a,q) ≤Lα(a,q)== %%POSTFIX%%.RVB gradient The gradient of th*
>%%LINK%%[[#^h47ukb9jp74|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^h47ukb9jp74


>%%
>```annotation-json
>{"created":"2023-08-06T13:56:32.103Z","text":"Need to give an intuitive view on this: \"basically, we can calculate the gradient using this formula, not important to understand fully\"","updated":"2023-08-06T13:56:32.103Z","document":{"title":"lievin23a.pdf","link":[{"href":"urn:x-pdf:ed2b119e8f77e065d14f1357b2c13c63"},{"href":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf"}],"documentFingerprint":"ed2b119e8f77e065d14f1357b2c13c63"},"uri":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf","target":[{"source":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf","selector":[{"type":"TextPositionSelector","start":8236,"end":8454},{"type":"TextQuoteSelector","exact":"RVB gradient The gradient of the RVB w.r.t. θ is:∇θLα(a,q) = Erφ[ ̃w1−αθ,φ (a,q,d) ∇θ log pθ(a,d|q)]where the normalized importance weight is defined as ̃w1−αθ,φ (a,d) := w1−αθ,φ (a,q,d)Erφ(d′|a,q)[w1−αθ,φ (a,d′,q)] . ","prefix":"log pθ(a|q) LKα (a,q) ≤Lα(a,q) .","suffix":"(5)In this paper, we consider th"}]}]}
>```
>%%
>*%%PREFIX%%log pθ(a|q) LKα (a,q) ≤Lα(a,q) .%%HIGHLIGHT%% ==RVB gradient The gradient of the RVB w.r.t. θ is:∇θLα(a,q) = Erφ[ ̃w1−αθ,φ (a,q,d) ∇θ log pθ(a,d|q)]where the normalized importance weight is defined as ̃w1−αθ,φ (a,d) := w1−αθ,φ (a,q,d)Erφ(d′|a,q)[w1−αθ,φ (a,d′,q)] .== %%POSTFIX%%(5)In this paper, we consider th*
>%%LINK%%[[#^y5l8ihnppfd|show annotation]]
>%%COMMENT%%
>Need to give an intuitive view on this: "basically, we can calculate the gradient using this formula, not important to understand fully"
>%%TAGS%%
>
^y5l8ihnppfd


>%%
>```annotation-json
>{"created":"2023-08-06T13:58:02.613Z","text":"Q: I guess this is a fair assumption? \n\nWould the results be better if they DID do gradient wrt approx post $r_\\phi$? \n\nThough would any gains just not be worth the extra computational requirements/params?\n\nA: Having phi fixed and only updated every T steps is a pretty integral part of this method.","updated":"2023-08-06T13:58:02.613Z","document":{"title":"lievin23a.pdf","link":[{"href":"urn:x-pdf:ed2b119e8f77e065d14f1357b2c13c63"},{"href":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf"}],"documentFingerprint":"ed2b119e8f77e065d14f1357b2c13c63"},"uri":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf","target":[{"source":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf","selector":[{"type":"TextPositionSelector","start":8457,"end":8600},{"type":"TextQuoteSelector","exact":"In this paper, we consider the sampling distribution rφ to bestatic and therefore do not estimate the gradient w.r.t. theapproximate posterior.","prefix":"(d′|a,q)[w1−αθ,φ (a,d′,q)] . (5)","suffix":" Optimizing the parameter φ join"}]}]}
>```
>%%
>*%%PREFIX%%(d′|a,q)[w1−αθ,φ (a,d′,q)] . (5)%%HIGHLIGHT%% ==In this paper, we consider the sampling distribution rφ to bestatic and therefore do not estimate the gradient w.r.t. theapproximate posterior.== %%POSTFIX%%Optimizing the parameter φ join*
>%%LINK%%[[#^gkpe16uy2ou|show annotation]]
>%%COMMENT%%
>Q: I guess this is a fair assumption? 
>
>Would the results be better if they DID do gradient wrt approx post $r_\phi$? 
>
>Though would any gains just not be worth the extra computational requirements/params?
>
>A: Having phi fixed and only updated every T steps is a pretty integral part of this method.
>%%TAGS%%
>
^gkpe16uy2ou


>%%
>```annotation-json
>{"created":"2023-08-06T14:01:23.066Z","text":"DEFINITELY USE","updated":"2023-08-06T14:01:23.066Z","document":{"title":"lievin23a.pdf","link":[{"href":"urn:x-pdf:ed2b119e8f77e065d14f1357b2c13c63"},{"href":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf"}],"documentFingerprint":"ed2b119e8f77e065d14f1357b2c13c63"},"uri":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf","target":[{"source":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf","selector":[{"type":"TextPositionSelector","start":6695,"end":6703},{"type":"TextQuoteSelector","exact":"Figure 2","prefix":"Divergence Variational Inference","suffix":". Depicts the core component of "}]}]}
>```
>%%
>*%%PREFIX%%Divergence Variational Inference%%HIGHLIGHT%% ==Figure 2== %%POSTFIX%%. Depicts the core component of*
>%%LINK%%[[#^92xind9jm7|show annotation]]
>%%COMMENT%%
>DEFINITELY USE
>%%TAGS%%
>
^92xind9jm7


>%%
>```annotation-json
>{"created":"2023-08-06T14:02:32.554Z","text":"should this not be \"as K increases and $\\alpha \\to 0^+$\"?","updated":"2023-08-06T14:02:32.554Z","document":{"title":"lievin23a.pdf","link":[{"href":"urn:x-pdf:ed2b119e8f77e065d14f1357b2c13c63"},{"href":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf"}],"documentFingerprint":"ed2b119e8f77e065d14f1357b2c13c63"},"uri":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf","target":[{"source":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf","selector":[{"type":"TextPositionSelector","start":6897,"end":6913},{"type":"TextQuoteSelector","exact":"α and K increase","prefix":"of samplesK ≥1. As the value of ","suffix":", the IW-RVB becomesa more accur"}]}]}
>```
>%%
>*%%PREFIX%%of samplesK ≥1. As the value of%%HIGHLIGHT%% ==α and K increase== %%POSTFIX%%, the IW-RVB becomesa more accur*
>%%LINK%%[[#^c6medmxo9p|show annotation]]
>%%COMMENT%%
>should this not be "as K increases and $\alpha \to 0^+$"?
>%%TAGS%%
>
^c6medmxo9p


>%%
>```annotation-json
>{"created":"2023-08-06T14:03:39.005Z","text":"interesting\n","updated":"2023-08-06T14:03:39.005Z","document":{"title":"lievin23a.pdf","link":[{"href":"urn:x-pdf:ed2b119e8f77e065d14f1357b2c13c63"},{"href":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf"}],"documentFingerprint":"ed2b119e8f77e065d14f1357b2c13c63"},"uri":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf","target":[{"source":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf","selector":[{"type":"TextPositionSelector","start":9038,"end":9247},{"type":"TextQuoteSelector","exact":" we explore interpolating between variational boundsusing the parameter α of the RVB. We argue that, even fora non-trainable parameter φ, optimizing for a looser boundcan overcome early optimization challenges","prefix":" (e.g., the IWB).4 In thispaper,","suffix":".For α = 0, the RVB aligns with "}]}]}
>```
>%%
>*%%PREFIX%%(e.g., the IWB).4 In thispaper,%%HIGHLIGHT%% ==we explore interpolating between variational boundsusing the parameter α of the RVB. We argue that, even fora non-trainable parameter φ, optimizing for a looser boundcan overcome early optimization challenges== %%POSTFIX%%.For α = 0, the RVB aligns with*
>%%LINK%%[[#^jizg4c68i9l|show annotation]]
>%%COMMENT%%
>interesting
>
>%%TAGS%%
>
^jizg4c68i9l


>%%
>```annotation-json
>{"created":"2023-08-06T14:05:03.540Z","text":"introduce these closer to the original definitions of reader and retriever (or restate these definitions)","updated":"2023-08-06T14:05:03.540Z","document":{"title":"lievin23a.pdf","link":[{"href":"urn:x-pdf:ed2b119e8f77e065d14f1357b2c13c63"},{"href":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf"}],"documentFingerprint":"ed2b119e8f77e065d14f1357b2c13c63"},"uri":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf","target":[{"source":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf","selector":[{"type":"TextPositionSelector","start":9621,"end":9716},{"type":"TextQuoteSelector","exact":"∇θREAD. Lα=1(a,q) = Erφ(d|a,q) [∇θ log pθ(a|d,q)]∇θRETR. Lα=1(a,q) = −∇θDKL (rφ(d|a,q)∥pθ(d|q))","prefix":"der and retriever decomposes as:","suffix":" .Maximizing the ELBO correspond"}]}]}
>```
>%%
>*%%PREFIX%%der and retriever decomposes as:%%HIGHLIGHT%% ==∇θREAD. Lα=1(a,q) = Erφ(d|a,q) [∇θ log pθ(a|d,q)]∇θRETR. Lα=1(a,q) = −∇θDKL (rφ(d|a,q)∥pθ(d|q))== %%POSTFIX%%.Maximizing the ELBO correspond*
>%%LINK%%[[#^sfbvzk6o8y|show annotation]]
>%%COMMENT%%
>introduce these closer to the original definitions of reader and retriever (or restate these definitions)
>%%TAGS%%
>
^sfbvzk6o8y


>%%
>```annotation-json
>{"created":"2023-08-06T14:06:24.813Z","text":"WRITE THIS OUT CLEARLY AS A FRACTION - GOOD FOR REFERENCE WHEN WE TALK ABOUT KL AND STUFF","updated":"2023-08-06T14:06:24.813Z","document":{"title":"lievin23a.pdf","link":[{"href":"urn:x-pdf:ed2b119e8f77e065d14f1357b2c13c63"},{"href":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf"}],"documentFingerprint":"ed2b119e8f77e065d14f1357b2c13c63"},"uri":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf","target":[{"source":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf","selector":[{"type":"TextPositionSelector","start":7370,"end":7409},{"type":"TextQuoteSelector","exact":"w1−αθ,φ (a,q,d) :=pθ(a,d|q)r−1φ (d|a,q)","prefix":"α < 1 and the importance weight ","suffix":" the variational Rényi bound (RV"}]}]}
>```
>%%
>*%%PREFIX%%α < 1 and the importance weight%%HIGHLIGHT%% ==w1−αθ,φ (a,q,d) :=pθ(a,d|q)r−1φ (d|a,q)== %%POSTFIX%%the variational Rényi bound (RV*
>%%LINK%%[[#^qbu9t9pw9d9|show annotation]]
>%%COMMENT%%
>WRITE THIS OUT CLEARLY AS A FRACTION - GOOD FOR REFERENCE WHEN WE TALK ABOUT KL AND STUFF
>%%TAGS%%
>
^qbu9t9pw9d9


>%%
>```annotation-json
>{"created":"2023-08-06T14:07:48.423Z","text":"i like this","updated":"2023-08-06T14:07:48.423Z","document":{"title":"lievin23a.pdf","link":[{"href":"urn:x-pdf:ed2b119e8f77e065d14f1357b2c13c63"},{"href":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf"}],"documentFingerprint":"ed2b119e8f77e065d14f1357b2c13c63"},"uri":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf","target":[{"source":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf","selector":[{"type":"TextPositionSelector","start":9804,"end":10060},{"type":"TextQuoteSelector","exact":"On the reader side, this equalsmaximizing the answer likelihood pθ(a|d,q) in expectationover rφ(d|a,q) independently of the value of pθ(d|q). Onthe retriever side, this corresponds to matching the approx-imate posterior with the learned retriever pθ(d|q). ","prefix":"erand the retriever disjointly. ","suffix":"This4 Exploring using hybrid ELB"}]}]}
>```
>%%
>*%%PREFIX%%erand the retriever disjointly.%%HIGHLIGHT%% ==On the reader side, this equalsmaximizing the answer likelihood pθ(a|d,q) in expectationover rφ(d|a,q) independently of the value of pθ(d|q). Onthe retriever side, this corresponds to matching the approx-imate posterior with the learned retriever pθ(d|q).== %%POSTFIX%%This4 Exploring using hybrid ELB*
>%%LINK%%[[#^v3f1imzhhz|show annotation]]
>%%COMMENT%%
>i like this
>%%TAGS%%
>
^v3f1imzhhz


>%%
>```annotation-json
>{"created":"2023-08-06T14:08:29.251Z","text":"this is a good point\n\n(but not sure how to rephrase it more clearly---come back to this)","updated":"2023-08-06T14:08:29.251Z","document":{"title":"lievin23a.pdf","link":[{"href":"urn:x-pdf:ed2b119e8f77e065d14f1357b2c13c63"},{"href":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf"}],"documentFingerprint":"ed2b119e8f77e065d14f1357b2c13c63"},"uri":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf","target":[{"source":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf","selector":[{"type":"TextPositionSelector","start":10369,"end":10574},{"type":"TextQuoteSelector","exact":"f knowledge distillation of theposterior into the retriever. After an initial learning phase,the RVB can be smoothly interpolated from the ELBO tothe marginal task likelihood by controlling the parameter α","prefix":"ing.can be seen as an instance o","suffix":".2.2. VOD objectiveIn ODQA appli"}]}]}
>```
>%%
>*%%PREFIX%%ing.can be seen as an instance o%%HIGHLIGHT%% ==f knowledge distillation of theposterior into the retriever. After an initial learning phase,the RVB can be smoothly interpolated from the ELBO tothe marginal task likelihood by controlling the parameter α== %%POSTFIX%%.2.2. VOD objectiveIn ODQA appli*
>%%LINK%%[[#^n4ru9ptb2n|show annotation]]
>%%COMMENT%%
>this is a good point
>
>(but not sure how to rephrase it more clearly---come back to this)
>%%TAGS%%
>
^n4ru9ptb2n


>%%
>```annotation-json
>{"created":"2023-08-06T14:11:36.754Z","text":"to be clear, (3) is an importance sampling-based approximation of (2) ($\\mathbb{E} \\to \\Sigma$)\n\n\n\"The VOD objective is a self-normalized importance sampling estimate of the RVB, whereas the IW-RVB is a standard\nimportance sampling. The VOD objective only differs from the IW-RVB because (i) VOD relies on self-normalized priority\nsampling eq. (28a), (ii) the normalizing constant ZθZ−1\nφ in the expression of the importance weight wθ,φ(a,q,d) is\nestimated with a self-normalized priority sampling estimate eq. (28b).\" from pg 17","updated":"2023-08-06T14:11:36.754Z","document":{"title":"lievin23a.pdf","link":[{"href":"urn:x-pdf:ed2b119e8f77e065d14f1357b2c13c63"},{"href":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf"}],"documentFingerprint":"ed2b119e8f77e065d14f1357b2c13c63"},"uri":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf","target":[{"source":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf","selector":[{"type":"TextPositionSelector","start":7879,"end":7951},{"type":"TextQuoteSelector","exact":"LKα (a,q) := 11 −α log 1KK∑i=1w1−αθ,φ (a,q,di) (3)d1,...,dKiid∼ rφ(d|a,q","prefix":"B (IW-RVB; Li & Turner (2016)):ˆ","suffix":")which aligns with the importanc"}]}]}
>```
>%%
>*%%PREFIX%%B (IW-RVB; Li & Turner (2016)):ˆ%%HIGHLIGHT%% ==LKα (a,q) := 11 −α log 1KK∑i=1w1−αθ,φ (a,q,di) (3)d1,...,dKiid∼ rφ(d|a,q== %%POSTFIX%%)which aligns with the importanc*
>%%LINK%%[[#^dhlusq5cbci|show annotation]]
>%%COMMENT%%
>to be clear, (3) is an importance sampling-based approximation of (2) ($\mathbb{E} \to \Sigma$)
>
>
>"The VOD objective is a self-normalized importance sampling estimate of the RVB, whereas the IW-RVB is a standard
>importance sampling. The VOD objective only differs from the IW-RVB because (i) VOD relies on self-normalized priority
>sampling eq. (28a), (ii) the normalizing constant ZθZ−1
>φ in the expression of the importance weight wθ,φ(a,q,d) is
>estimated with a self-normalized priority sampling estimate eq. (28b)." from pg 17
>%%TAGS%%
>
^dhlusq5cbci


>%%
>```annotation-json
>{"created":"2023-08-06T14:13:38.074Z","text":"there MUST be a way of not going into this minute detail in the prez","updated":"2023-08-06T14:13:38.074Z","document":{"title":"lievin23a.pdf","link":[{"href":"urn:x-pdf:ed2b119e8f77e065d14f1357b2c13c63"},{"href":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf"}],"documentFingerprint":"ed2b119e8f77e065d14f1357b2c13c63"},"uri":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf","target":[{"source":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf","selector":[{"type":"TextPositionSelector","start":11095,"end":11164},{"type":"TextQuoteSelector","exact":"ζ(d) ∝pθ(d|q)r−1φ (d|a,q) as:ˆvθ,φ := pθ(a|q,di)ζ(di)K∑j=1sjζ(dj)","prefix":"rmalized retrieval density ratio","suffix":"−1(7)The set of documents d1,..."}]}]}
>```
>%%
>*%%PREFIX%%rmalized retrieval density ratio%%HIGHLIGHT%% ==ζ(d) ∝pθ(d|q)r−1φ (d|a,q) as:ˆvθ,φ := pθ(a|q,di)ζ(di)K∑j=1sjζ(dj)== %%POSTFIX%%−1(7)The set of documents d1,...*
>%%LINK%%[[#^yepp6jqim|show annotation]]
>%%COMMENT%%
>there MUST be a way of not going into this minute detail in the prez
>%%TAGS%%
>
^yepp6jqim


>%%
>```annotation-json
>{"created":"2023-08-06T14:16:37.819Z","text":"other than Appendix A, see https://webdocs.cs.ualberta.ca/~mreza/courses/Streaming19/lecture10.pdf\n\n(actual ref is https://nickduffield.net/download/papers/priority.pdf )","updated":"2023-08-06T14:16:37.819Z","document":{"title":"lievin23a.pdf","link":[{"href":"urn:x-pdf:ed2b119e8f77e065d14f1357b2c13c63"},{"href":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf"}],"documentFingerprint":"ed2b119e8f77e065d14f1357b2c13c63"},"uri":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf","target":[{"source":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf","selector":[{"type":"TextPositionSelector","start":11254,"end":11296},{"type":"TextQuoteSelector","exact":"priority sam-pling (Duffield et al., 2007)","prefix":"eplacement from rφ(d|a,q) using ","suffix":". The sampling proce-dure comes "}]}]}
>```
>%%
>*%%PREFIX%%eplacement from rφ(d|a,q) using%%HIGHLIGHT%% ==priority sam-pling (Duffield et al., 2007)== %%POSTFIX%%. The sampling proce-dure comes*
>%%LINK%%[[#^189w06ilqlii|show annotation]]
>%%COMMENT%%
>other than Appendix A, see https://webdocs.cs.ualberta.ca/~mreza/courses/Streaming19/lecture10.pdf
>
>(actual ref is https://nickduffield.net/download/papers/priority.pdf )
>%%TAGS%%
>
^189w06ilqlii


>%%
>```annotation-json
>{"created":"2023-08-06T14:18:10.032Z","text":"nice little point","updated":"2023-08-06T14:18:10.032Z","document":{"title":"lievin23a.pdf","link":[{"href":"urn:x-pdf:ed2b119e8f77e065d14f1357b2c13c63"},{"href":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf"}],"documentFingerprint":"ed2b119e8f77e065d14f1357b2c13c63"},"uri":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf","target":[{"source":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf","selector":[{"type":"TextPositionSelector","start":11626,"end":11697},{"type":"TextQuoteSelector","exact":"evaluated with complexity O(K),whereas the IW-RVB is of complexity O(N)","prefix":"th proba-bility one) and can be ","suffix":". Further-more, the VOD objectiv"}]}]}
>```
>%%
>*%%PREFIX%%th proba-bility one) and can be%%HIGHLIGHT%% ==evaluated with complexity O(K),whereas the IW-RVB is of complexity O(N)== %%POSTFIX%%. Further-more, the VOD objectiv*
>%%LINK%%[[#^u66nhsxdi1|show annotation]]
>%%COMMENT%%
>nice little point
>%%TAGS%%
>
^u66nhsxdi1


>%%
>```annotation-json
>{"created":"2023-08-06T14:19:21.143Z","text":"i like this point","updated":"2023-08-06T14:19:21.143Z","document":{"title":"lievin23a.pdf","link":[{"href":"urn:x-pdf:ed2b119e8f77e065d14f1357b2c13c63"},{"href":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf"}],"documentFingerprint":"ed2b119e8f77e065d14f1357b2c13c63"},"uri":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf","target":[{"source":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf","selector":[{"type":"TextPositionSelector","start":12588,"end":12700},{"type":"TextQuoteSelector","exact":" only Pdocuments need to be stored in memory, and ii) the valueP serves as an exploration-exploitation threshold","prefix":"retention of document scores, as","suffix":": a highervalue of P yield great"}]}]}
>```
>%%
>*%%PREFIX%%retention of document scores, as%%HIGHLIGHT%% ==only Pdocuments need to be stored in memory, and ii) the valueP serves as an exploration-exploitation threshold== %%POSTFIX%%: a highervalue of P yield great*
>%%LINK%%[[#^4dgeutlhi2l|show annotation]]
>%%COMMENT%%
>i like this point
>%%TAGS%%
>
^4dgeutlhi2l


>%%
>```annotation-json
>{"created":"2023-08-06T14:21:05.944Z","text":"Q: so if I'm understanding correctly: this is just saying that both $f_\\theta$, the *true(?)/prior(?) retriever* ($p_\\theta (\\mathbf{d}|\\mathbf{q})$) score function, and $f_\\phi$, the *approx posterior (\"static retriever\" on pg 28)* ($r_\\phi (\\mathbf{d}|\\mathbf{a}, \\mathbf{q})$) can be modelled as the output embeddings from LLMs like BERT?\n\nA: essentially, yeah. (But BM25 could also be used for $f_\\phi$ (or $f_\\theta$), or a hybrid thereof)","updated":"2023-08-06T14:21:05.944Z","document":{"title":"lievin23a.pdf","link":[{"href":"urn:x-pdf:ed2b119e8f77e065d14f1357b2c13c63"},{"href":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf"}],"documentFingerprint":"ed2b119e8f77e065d14f1357b2c13c63"},"uri":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf","target":[{"source":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf","selector":[{"type":"TextPositionSelector","start":13285,"end":13449},{"type":"TextQuoteSelector","exact":"The score function fθ and fφcan be implemented using BM25 and/or contextual vectorrepresentations extracted using pretrained language mod-els such as DPR or ColBERT","prefix":"s rankedby the score fφ(a,q,d). ","suffix":" (Karpukhin et al., 2020;Khattab"}]}]}
>```
>%%
>*%%PREFIX%%s rankedby the score fφ(a,q,d).%%HIGHLIGHT%% ==The score function fθ and fφcan be implemented using BM25 and/or contextual vectorrepresentations extracted using pretrained language mod-els such as DPR or ColBERT== %%POSTFIX%%(Karpukhin et al., 2020;Khattab*
>%%LINK%%[[#^0r3339ct5fof|show annotation]]
>%%COMMENT%%
>Q: so if I'm understanding correctly: this is just saying that both $f_\theta$, the *true(?)/prior(?) retriever* ($p_\theta (\mathbf{d}|\mathbf{q})$) score function, and $f_\phi$, the *approx posterior ("static retriever" on pg 28)* ($r_\phi (\mathbf{d}|\mathbf{a}, \mathbf{q})$) can be modelled as the output embeddings from LLMs like BERT?
>
>A: essentially, yeah. (But BM25 could also be used for $f_\phi$ (or $f_\theta$), or a hybrid thereof)
>%%TAGS%%
>
^0r3339ct5fof


>%%
>```annotation-json
>{"created":"2023-08-06T14:28:06.801Z","text":"include nearer end of prez","updated":"2023-08-06T14:28:06.801Z","document":{"title":"lievin23a.pdf","link":[{"href":"urn:x-pdf:ed2b119e8f77e065d14f1357b2c13c63"},{"href":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf"}],"documentFingerprint":"ed2b119e8f77e065d14f1357b2c13c63"},"uri":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf","target":[{"source":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf","selector":[{"type":"TextPositionSelector","start":13928,"end":14244},{"type":"TextQuoteSelector","exact":"Nevertheless, VOD is general-purpose and designed for latent variable models defined ona discrete and finite space. In NLP, it applies to a wide rangeof settings such as generative, extractive, multiple-choiceODQA as well as retrieval-augmented language modelling.Find a non-exhaustive list of examples in Appendix E","prefix":"ameworkto multiple-choice ODQA. ","suffix":".3. Related workVOD aids the dev"}]}]}
>```
>%%
>*%%PREFIX%%ameworkto multiple-choice ODQA.%%HIGHLIGHT%% ==Nevertheless, VOD is general-purpose and designed for latent variable models defined ona discrete and finite space. In NLP, it applies to a wide rangeof settings such as generative, extractive, multiple-choiceODQA as well as retrieval-augmented language modelling.Find a non-exhaustive list of examples in Appendix E== %%POSTFIX%%.3. Related workVOD aids the dev*
>%%LINK%%[[#^e2914ne503p|show annotation]]
>%%COMMENT%%
>include nearer end of prez
>%%TAGS%%
>
^e2914ne503p


>%%
>```annotation-json
>{"created":"2023-08-06T14:29:25.361Z","text":"probably just ignore this in prez","updated":"2023-08-06T14:29:25.361Z","document":{"title":"lievin23a.pdf","link":[{"href":"urn:x-pdf:ed2b119e8f77e065d14f1357b2c13c63"},{"href":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf"}],"documentFingerprint":"ed2b119e8f77e065d14f1357b2c13c63"},"uri":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf","target":[{"source":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf","selector":[{"type":"TextPositionSelector","start":14248,"end":14260},{"type":"TextQuoteSelector","exact":"Related work","prefix":"st of examples in Appendix E.3. ","suffix":"VOD aids the development of retr"}]}]}
>```
>%%
>*%%PREFIX%%st of examples in Appendix E.3.%%HIGHLIGHT%% ==Related work== %%POSTFIX%%VOD aids the development of retr*
>%%LINK%%[[#^tx4ozn3aa1e|show annotation]]
>%%COMMENT%%
>probably just ignore this in prez
>%%TAGS%%
>
^tx4ozn3aa1e


>%%
>```annotation-json
>{"created":"2023-08-06T14:32:09.199Z","text":"maybe interesting?? (worth reading, but perhaps not prezzing)","updated":"2023-08-06T14:32:09.199Z","document":{"title":"lievin23a.pdf","link":[{"href":"urn:x-pdf:ed2b119e8f77e065d14f1357b2c13c63"},{"href":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf"}],"documentFingerprint":"ed2b119e8f77e065d14f1357b2c13c63"},"uri":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf","target":[{"source":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf","selector":[{"type":"TextPositionSelector","start":18257,"end":18341},{"type":"TextQuoteSelector","exact":"In Appendix D, we showthat the top-K MLL is a special case of VOD for K = Pand α = 0","prefix":"ing the retriever distribution. ","suffix":".4. ExperimentsIn this section, "}]}]}
>```
>%%
>*%%PREFIX%%ing the retriever distribution.%%HIGHLIGHT%% ==In Appendix D, we showthat the top-K MLL is a special case of VOD for K = Pand α = 0== %%POSTFIX%%.4. ExperimentsIn this section,*
>%%LINK%%[[#^3rnycve3j23|show annotation]]
>%%COMMENT%%
>maybe interesting?? (worth reading, but perhaps not prezzing)
>%%TAGS%%
>
^3rnycve3j23


>%%
>```annotation-json
>{"created":"2023-08-06T14:32:42.965Z","updated":"2023-08-06T14:32:42.965Z","document":{"title":"lievin23a.pdf","link":[{"href":"urn:x-pdf:ed2b119e8f77e065d14f1357b2c13c63"},{"href":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf"}],"documentFingerprint":"ed2b119e8f77e065d14f1357b2c13c63"},"uri":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf","target":[{"source":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf","selector":[{"type":"TextPositionSelector","start":18659,"end":18718},{"type":"TextQuoteSelector","exact":"MedWiki, a subset ofWikipedia targeted to medical QA tasks.","prefix":"ed in Table 2. We introduce the ","suffix":"MedMCQA Pal et al. (2022) is a l"}]}]}
>```
>%%
>*%%PREFIX%%ed in Table 2. We introduce the%%HIGHLIGHT%% ==MedWiki, a subset ofWikipedia targeted to medical QA tasks.== %%POSTFIX%%MedMCQA Pal et al. (2022) is a l*
>%%LINK%%[[#^lf1ewrizffp|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^lf1ewrizffp


>%%
>```annotation-json
>{"created":"2023-08-06T14:33:04.383Z","text":"summarise in pres with one sentence: \"Evaluated with some medical Q&A datasets\"","updated":"2023-08-06T14:33:04.383Z","document":{"title":"lievin23a.pdf","link":[{"href":"urn:x-pdf:ed2b119e8f77e065d14f1357b2c13c63"},{"href":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf"}],"documentFingerprint":"ed2b119e8f77e065d14f1357b2c13c63"},"uri":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf","target":[{"source":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf","selector":[{"type":"TextPositionSelector","start":18561,"end":18569},{"type":"TextQuoteSelector","exact":"Datasets","prefix":"s are available on GitHub.84.1. ","suffix":"The datasets utilized for the me"}]}]}
>```
>%%
>*%%PREFIX%%s are available on GitHub.84.1.%%HIGHLIGHT%% ==Datasets== %%POSTFIX%%The datasets utilized for the me*
>%%LINK%%[[#^97xwbe6pgx|show annotation]]
>%%COMMENT%%
>summarise in pres with one sentence: "Evaluated with some medical Q&A datasets"
>%%TAGS%%
>
^97xwbe6pgx


>%%
>```annotation-json
>{"created":"2023-08-06T14:39:26.309Z","text":"i.e. the set of all possible sets of $M$ documents from the corpus of $N$ documents (chosen with replacement)","updated":"2023-08-06T14:39:26.309Z","document":{"title":"lievin23a.pdf","link":[{"href":"urn:x-pdf:ed2b119e8f77e065d14f1357b2c13c63"},{"href":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf"}],"documentFingerprint":"ed2b119e8f77e065d14f1357b2c13c63"},"uri":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf","target":[{"source":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf","selector":[{"type":"TextPositionSelector","start":21254,"end":21296},{"type":"TextQuoteSelector","exact":"D(M), which contains NM document vec-tors.","prefix":"f M combinationsof documents as ","suffix":" The marginal likelihood is defi"}]}]}
>```
>%%
>*%%PREFIX%%f M combinationsof documents as%%HIGHLIGHT%% ==D(M), which contains NM document vec-tors.== %%POSTFIX%%The marginal likelihood is defi*
>%%LINK%%[[#^uk7xfxkk1w|show annotation]]
>%%COMMENT%%
>i.e. the set of all possible sets of $M$ documents from the corpus of $N$ documents (chosen with replacement)
>%%TAGS%%
>
^uk7xfxkk1w


>%%
>```annotation-json
>{"created":"2023-08-06T14:42:14.732Z","updated":"2023-08-06T14:42:14.732Z","document":{"title":"lievin23a.pdf","link":[{"href":"urn:x-pdf:ed2b119e8f77e065d14f1357b2c13c63"},{"href":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf"}],"documentFingerprint":"ed2b119e8f77e065d14f1357b2c13c63"},"uri":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf","target":[{"source":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf","selector":[{"type":"TextPositionSelector","start":21718,"end":21793},{"type":"TextQuoteSelector","exact":"these models are parameterized by scores fθ(d,qj) andfφ(d,qj) respectively.","prefix":"ption. As described in eq. (8a),","suffix":" The reader and retriever models"}]}]}
>```
>%%
>*%%PREFIX%%ption. As described in eq. (8a),%%HIGHLIGHT%% ==these models are parameterized by scores fθ(d,qj) andfφ(d,qj) respectively.== %%POSTFIX%%The reader and retriever models*
>%%LINK%%[[#^5faaptun63w|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^5faaptun63w


>%%
>```annotation-json
>{"created":"2023-08-06T14:43:42.560Z","text":"need to sit with this a bit","updated":"2023-08-06T14:43:42.560Z","document":{"title":"lievin23a.pdf","link":[{"href":"urn:x-pdf:ed2b119e8f77e065d14f1357b2c13c63"},{"href":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf"}],"documentFingerprint":"ed2b119e8f77e065d14f1357b2c13c63"},"uri":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf","target":[{"source":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf","selector":[{"type":"TextPositionSelector","start":22141,"end":22234},{"type":"TextQuoteSelector","exact":"the VOD objective in a multiple-choice setting implies theretrieval of KM documents per query","prefix":"defined in eq. (9). In practice,","suffix":", resulting in a condi-tional an"}]}]}
>```
>%%
>*%%PREFIX%%defined in eq. (9). In practice,%%HIGHLIGHT%% ==the VOD objective in a multiple-choice setting implies theretrieval of KM documents per query== %%POSTFIX%%, resulting in a condi-tional an*
>%%LINK%%[[#^ife68lmngfs|show annotation]]
>%%COMMENT%%
>need to sit with this a bit
>%%TAGS%%
>
^ife68lmngfs


>%%
>```annotation-json
>{"created":"2023-08-06T14:46:12.226Z","text":"interesting, but perhaps not *essential* to the prez\n\n... actually it probably is important for the prez to show the knowledge distillation happening in the first T training steps whilst $\\alpha$ is annealed from 1 to 0","updated":"2023-08-06T14:46:12.226Z","document":{"title":"lievin23a.pdf","link":[{"href":"urn:x-pdf:ed2b119e8f77e065d14f1357b2c13c63"},{"href":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf"}],"documentFingerprint":"ed2b119e8f77e065d14f1357b2c13c63"},"uri":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf","target":[{"source":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf","selector":[{"type":"TextPositionSelector","start":22923,"end":22951},{"type":"TextQuoteSelector","exact":"Hybrid approximate posterior","prefix":"ails can be found in Appendix F.","suffix":" We parameterize thescore fφ of "}]}]}
>```
>%%
>*%%PREFIX%%ails can be found in Appendix F.%%HIGHLIGHT%% ==Hybrid approximate posterior== %%POSTFIX%%We parameterize thescore fφ of*
>%%LINK%%[[#^8uhz1yxuplt|show annotation]]
>%%COMMENT%%
>interesting, but perhaps not *essential* to the prez
>
>... actually it probably is important for the prez to show the knowledge distillation happening in the first T training steps whilst $\alpha$ is annealed from 1 to 0
>%%TAGS%%
>
^8uhz1yxuplt


>%%
>```annotation-json
>{"created":"2023-08-06T14:46:42.707Z","updated":"2023-08-06T14:46:42.707Z","document":{"title":"lievin23a.pdf","link":[{"href":"urn:x-pdf:ed2b119e8f77e065d14f1357b2c13c63"},{"href":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf"}],"documentFingerprint":"ed2b119e8f77e065d14f1357b2c13c63"},"uri":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf","target":[{"source":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf","selector":[{"type":"TextPositionSelector","start":23227,"end":23393},{"type":"TextQuoteSelector","exact":"β is a parameter scaled proportionally tothe ratio of question and answer lengths Lq/La to ensurethat the BM25 score of the question does not outweigh theanswer score","prefix":" β ·BM25(a,d)) .where τ = 5 and ","suffix":". We use β = 1 + 0.5 max {0,log "}]}]}
>```
>%%
>*%%PREFIX%%β ·BM25(a,d)) .where τ = 5 and%%HIGHLIGHT%% ==β is a parameter scaled proportionally tothe ratio of question and answer lengths Lq/La to ensurethat the BM25 score of the question does not outweigh theanswer score== %%POSTFIX%%. We use β = 1 + 0.5 max {0,log*
>%%LINK%%[[#^l95w0tkk88f|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^l95w0tkk88f


>%%
>```annotation-json
>{"created":"2023-08-06T14:50:28.201Z","text":"not 100% sure what this means\n\n... it means that with $alpha =1$ the VOD=ELBO, so we get that nice knowledge distillation between $f_\\phi$ and $f_theta$ as we decrease $D_{KL}(r_\\phi(\\mathbf{d}|\\mathbf{q}) || p_\\theta(\\mathbf{d}|\\mathbf{q}))$.","updated":"2023-08-06T14:50:28.201Z","document":{"title":"lievin23a.pdf","link":[{"href":"urn:x-pdf:ed2b119e8f77e065d14f1357b2c13c63"},{"href":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf"}],"documentFingerprint":"ed2b119e8f77e065d14f1357b2c13c63"},"uri":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf","target":[{"source":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf","selector":[{"type":"TextPositionSelector","start":24202,"end":24419},{"type":"TextQuoteSelector","exact":"During thefirst round, we anneal the RVB parameter α from 1 to 0 tostabilize early training by distilling the BM25 cached scorefφ(a,d,q) = 0 + τ−1 (BM25(q,d) + β ·BM25(a,d))into the trainable retriever score fθ(d,q), ","prefix":"od where fckptφ is set to zero. ","suffix":"as shown in Fig-ure 3. At each t"}]}]}
>```
>%%
>*%%PREFIX%%od where fckptφ is set to zero.%%HIGHLIGHT%% ==During thefirst round, we anneal the RVB parameter α from 1 to 0 tostabilize early training by distilling the BM25 cached scorefφ(a,d,q) = 0 + τ−1 (BM25(q,d) + β ·BM25(a,d))into the trainable retriever score fθ(d,q),== %%POSTFIX%%as shown in Fig-ure 3. At each t*
>%%LINK%%[[#^n1pao4wsayh|show annotation]]
>%%COMMENT%%
>not 100% sure what this means
>
>... it means that with $alpha =1$ the VOD=ELBO, so we get that nice knowledge distillation between $f_\phi$ and $f_theta$ as we decrease $D_{KL}(r_\phi(\mathbf{d}|\mathbf{q}) || p_\theta(\mathbf{d}|\mathbf{q}))$.
>%%TAGS%%
>
^n1pao4wsayh


>%%
>```annotation-json
>{"created":"2023-08-06T14:52:57.215Z","text":"include but don't dwell on table","updated":"2023-08-06T14:52:57.215Z","document":{"title":"lievin23a.pdf","link":[{"href":"urn:x-pdf:ed2b119e8f77e065d14f1357b2c13c63"},{"href":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf"}],"documentFingerprint":"ed2b119e8f77e065d14f1357b2c13c63"},"uri":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf","target":[{"source":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf","selector":[{"type":"TextPositionSelector","start":26240,"end":26287},{"type":"TextQuoteSelector","exact":"able 3. Open-domain question answering accuracy","prefix":" Open-Domain Question AnsweringT","suffix":".MedMCQA USMLEMethod Params. Fin"}]}]}
>```
>%%
>*%%PREFIX%%Open-Domain Question AnsweringT%%HIGHLIGHT%% ==able 3. Open-domain question answering accuracy== %%POSTFIX%%.MedMCQA USMLEMethod Params. Fin*
>%%LINK%%[[#^hqd6vjtzonv|show annotation]]
>%%COMMENT%%
>include but don't dwell on table
>%%TAGS%%
>
^hqd6vjtzonv


>%%
>```annotation-json
>{"created":"2023-08-06T14:53:10.455Z","text":"include but don't dwell on table","updated":"2023-08-06T14:53:10.455Z","document":{"title":"lievin23a.pdf","link":[{"href":"urn:x-pdf:ed2b119e8f77e065d14f1357b2c13c63"},{"href":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf"}],"documentFingerprint":"ed2b119e8f77e065d14f1357b2c13c63"},"uri":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf","target":[{"source":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf","selector":[{"type":"TextPositionSelector","start":28981,"end":29019},{"type":"TextQuoteSelector","exact":"able 4. Zero-shot accuracy on MMLU (%)","prefix":"tion gθ(d,q) = BERT(q)TBERT(d).T","suffix":".Task Subcategory Unified QA GPT"}]}]}
>```
>%%
>*%%PREFIX%%tion gθ(d,q) = BERT(q)TBERT(d).T%%HIGHLIGHT%% ==able 4. Zero-shot accuracy on MMLU (%)== %%POSTFIX%%.Task Subcategory Unified QA GPT*
>%%LINK%%[[#^62hm8gveue6|show annotation]]
>%%COMMENT%%
>include but don't dwell on table
>%%TAGS%%
>
^62hm8gveue6


>%%
>```annotation-json
>{"created":"2023-08-06T14:55:01.721Z","text":"this seems v important, but I'm not sure I fully understand everything this figure is saying\n\n...I think I get it now","updated":"2023-08-06T14:55:01.721Z","document":{"title":"lievin23a.pdf","link":[{"href":"urn:x-pdf:ed2b119e8f77e065d14f1357b2c13c63"},{"href":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf"}],"documentFingerprint":"ed2b119e8f77e065d14f1357b2c13c63"},"uri":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf","target":[{"source":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf","selector":[{"type":"TextPositionSelector","start":24616,"end":24625},{"type":"TextQuoteSelector","exact":"Figure 3.","prefix":"rparameter search was performed.","suffix":" During training, VOD incorporat"}]}]}
>```
>%%
>*%%PREFIX%%rparameter search was performed.%%HIGHLIGHT%% ==Figure 3.== %%POSTFIX%%During training, VOD incorporat*
>%%LINK%%[[#^e56xtazjg3n|show annotation]]
>%%COMMENT%%
>this seems v important, but I'm not sure I fully understand everything this figure is saying
>
>...I think I get it now
>%%TAGS%%
>
^e56xtazjg3n


>%%
>```annotation-json
>{"created":"2023-08-06T14:53:34.292Z","text":"Q: rather than...?\n\n(do they ever try anything else? I'd be happy if not bc at least this encoder architecture makes sense to me)\n\nA: they might but it doesn't matter, basically they've just chosen nice scoring functions $f_\\theta, f_\\phi, g_\\theta$ (which we softmax over to get distributions) using BERT (and BM25)","updated":"2023-08-06T14:53:34.292Z","document":{"title":"lievin23a.pdf","link":[{"href":"urn:x-pdf:ed2b119e8f77e065d14f1357b2c13c63"},{"href":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf"}],"documentFingerprint":"ed2b119e8f77e065d14f1357b2c13c63"},"uri":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf","target":[{"source":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf","selector":[{"type":"TextPositionSelector","start":28872,"end":28979},{"type":"TextQuoteSelector","exact":"To reduce overall running costs, we used a dual-encoderreader with score function gθ(d,q) = BERT(q)TBERT(d)","prefix":"ethods to optimize the model.12 ","suffix":".Table 4. Zero-shot accuracy on "}]}]}
>```
>%%
>*%%PREFIX%%ethods to optimize the model.12%%HIGHLIGHT%% ==To reduce overall running costs, we used a dual-encoderreader with score function gθ(d,q) = BERT(q)TBERT(d)== %%POSTFIX%%.Table 4. Zero-shot accuracy on*
>%%LINK%%[[#^wt9vgwamkjn|show annotation]]
>%%COMMENT%%
>Q: rather than...?
>
>(do they ever try anything else? I'd be happy if not bc at least this encoder architecture makes sense to me)
>
>A: they might but it doesn't matter, basically they've just chosen nice scoring functions $f_\theta, f_\phi, g_\theta$ (which we softmax over to get distributions) using BERT (and BM25)
>%%TAGS%%
>
^wt9vgwamkjn


>%%
>```annotation-json
>{"created":"2023-08-06T14:56:32.259Z","text":"cool but probably not cool enough for the prez","updated":"2023-08-06T14:56:32.259Z","document":{"title":"lievin23a.pdf","link":[{"href":"urn:x-pdf:ed2b119e8f77e065d14f1357b2c13c63"},{"href":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf"}],"documentFingerprint":"ed2b119e8f77e065d14f1357b2c13c63"},"uri":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf","target":[{"source":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf","selector":[{"type":"TextPositionSelector","start":29921,"end":30048},{"type":"TextQuoteSelector","exact":"Using the highest valueof P = 100 resulted in a smaller effective sample size,13slower learning but ultimately higher accuracy.","prefix":"s-ing values of P ∈ {8,32,100}. ","suffix":"4.6. Information retrievalDespit"}]}]}
>```
>%%
>*%%PREFIX%%s-ing values of P ∈ {8,32,100}.%%HIGHLIGHT%% ==Using the highest valueof P = 100 resulted in a smaller effective sample size,13slower learning but ultimately higher accuracy.== %%POSTFIX%%4.6. Information retrievalDespit*
>%%LINK%%[[#^jox2wlyj6a7|show annotation]]
>%%COMMENT%%
>cool but probably not cool enough for the prez
>%%TAGS%%
>
^jox2wlyj6a7


>%%
>```annotation-json
>{"created":"2023-08-06T14:58:46.316Z","text":"ok","updated":"2023-08-06T14:58:46.316Z","document":{"title":"lievin23a.pdf","link":[{"href":"urn:x-pdf:ed2b119e8f77e065d14f1357b2c13c63"},{"href":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf"}],"documentFingerprint":"ed2b119e8f77e065d14f1357b2c13c63"},"uri":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf","target":[{"source":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf","selector":[{"type":"TextPositionSelector","start":87628,"end":87768},{"type":"TextQuoteSelector","exact":"Therefore the value of thedivergence is never zero because the divergence between the model and the BM25 retrieveris always strictly positiv","prefix":"er and a static BM25 component. ","suffix":"e.24Variational Open-Domain Ques"}]}]}
>```
>%%
>*%%PREFIX%%er and a static BM25 component.%%HIGHLIGHT%% ==Therefore the value of thedivergence is never zero because the divergence between the model and the BM25 retrieveris always strictly positiv== %%POSTFIX%%e.24Variational Open-Domain Ques*
>%%LINK%%[[#^a0unhvtwbna|show annotation]]
>%%COMMENT%%
>ok
>%%TAGS%%
>
^a0unhvtwbna


>%%
>```annotation-json
>{"created":"2023-08-06T15:00:33.117Z","text":"a cool section---worth including in prez if time permits","updated":"2023-08-06T15:00:33.117Z","document":{"title":"lievin23a.pdf","link":[{"href":"urn:x-pdf:ed2b119e8f77e065d14f1357b2c13c63"},{"href":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf"}],"documentFingerprint":"ed2b119e8f77e065d14f1357b2c13c63"},"uri":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf","target":[{"source":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf","selector":[{"type":"TextPositionSelector","start":30693,"end":30741},{"type":"TextQuoteSelector","exact":"Re-purposing MCQA retrievers for semantic search","prefix":"hich we visualize in Appendix G.","suffix":"The BioLinkBERT VOD model, train"}]}]}
>```
>%%
>*%%PREFIX%%hich we visualize in Appendix G.%%HIGHLIGHT%% ==Re-purposing MCQA retrievers for semantic search== %%POSTFIX%%The BioLinkBERT VOD model, train*
>%%LINK%%[[#^4v0anoe7zgr|show annotation]]
>%%COMMENT%%
>a cool section---worth including in prez if time permits
>%%TAGS%%
>
^4v0anoe7zgr


>%%
>```annotation-json
>{"created":"2023-08-06T15:02:27.786Z","text":"nice!","updated":"2023-08-06T15:02:27.786Z","document":{"title":"lievin23a.pdf","link":[{"href":"urn:x-pdf:ed2b119e8f77e065d14f1357b2c13c63"},{"href":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf"}],"documentFingerprint":"ed2b119e8f77e065d14f1357b2c13c63"},"uri":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf","target":[{"source":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf","selector":[{"type":"TextPositionSelector","start":33053,"end":33276},{"type":"TextQuoteSelector","exact":"able 5. Retrieval performances on the FindZebra benchmark for aBioLinkBERT retriever trained using VOD on MedMCQA and onetrained using task-specific distillation, with and without couplingwith a BM25 score during evaluation","prefix":"ghest-ranking one is essential.T","suffix":".Method Distillation MRR Hit@20V"}]}]}
>```
>%%
>*%%PREFIX%%ghest-ranking one is essential.T%%HIGHLIGHT%% ==able 5. Retrieval performances on the FindZebra benchmark for aBioLinkBERT retriever trained using VOD on MedMCQA and onetrained using task-specific distillation, with and without couplingwith a BM25 score during evaluation== %%POSTFIX%%.Method Distillation MRR Hit@20V*
>%%LINK%%[[#^47zey2fmcqa|show annotation]]
>%%COMMENT%%
>nice!
>%%TAGS%%
>
^47zey2fmcqa


>%%
>```annotation-json
>{"created":"2023-08-06T15:03:18.241Z","text":"this paper is good at knowledge based stuff like the entry-level med student info in MedMCQA, but larger models like PaLM and Codex are (probably?) better than the BERT implementation here for problems that require more reasoning (e.g. the USMLE dataset which is targeted at medical professionals, not students)","updated":"2023-08-06T15:03:18.241Z","document":{"title":"lievin23a.pdf","link":[{"href":"urn:x-pdf:ed2b119e8f77e065d14f1357b2c13c63"},{"href":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf"}],"documentFingerprint":"ed2b119e8f77e065d14f1357b2c13c63"},"uri":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf","target":[{"source":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf","selector":[{"type":"TextPositionSelector","start":33901,"end":33931},{"type":"TextQuoteSelector","exact":"Knowledge vs. Reasoning Tasks ","prefix":"ting on FZ queries.5. Discussion","suffix":"The VOD frameworkwas evaluated u"}]}]}
>```
>%%
>*%%PREFIX%%ting on FZ queries.5. Discussion%%HIGHLIGHT%% ==Knowledge vs. Reasoning Tasks== %%POSTFIX%%The VOD frameworkwas evaluated u*
>%%LINK%%[[#^58lnwcouq4q|show annotation]]
>%%COMMENT%%
>this paper is good at knowledge based stuff like the entry-level med student info in MedMCQA, but larger models like PaLM and Codex are (probably?) better than the BERT implementation here for problems that require more reasoning (e.g. the USMLE dataset which is targeted at medical professionals, not students)
>%%TAGS%%
>
^58lnwcouq4q


>%%
>```annotation-json
>{"created":"2023-08-06T15:05:37.169Z","updated":"2023-08-06T15:05:37.169Z","document":{"title":"lievin23a.pdf","link":[{"href":"urn:x-pdf:ed2b119e8f77e065d14f1357b2c13c63"},{"href":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf"}],"documentFingerprint":"ed2b119e8f77e065d14f1357b2c13c63"},"uri":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf","target":[{"source":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf","selector":[{"type":"TextPositionSelector","start":35105,"end":35211},{"type":"TextQuoteSelector","exact":"Pretraining on MedMCQA improved downstream USMLEaccuracy by +10.3% when compared to training on USMLE only","prefix":"augmented language modelling.16 ","suffix":".8Variational Open-Domain Questi"}]}]}
>```
>%%
>*%%PREFIX%%augmented language modelling.16%%HIGHLIGHT%% ==Pretraining on MedMCQA improved downstream USMLEaccuracy by +10.3% when compared to training on USMLE only== %%POSTFIX%%.8Variational Open-Domain Questi*
>%%LINK%%[[#^eoqfn0howi|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^eoqfn0howi


>%%
>```annotation-json
>{"created":"2023-08-06T15:06:40.997Z","text":"BIGG---can definitely get some use out of this","updated":"2023-08-06T15:06:40.997Z","document":{"title":"lievin23a.pdf","link":[{"href":"urn:x-pdf:ed2b119e8f77e065d14f1357b2c13c63"},{"href":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf"}],"documentFingerprint":"ed2b119e8f77e065d14f1357b2c13c63"},"uri":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf","target":[{"source":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf","selector":[{"type":"TextPositionSelector","start":31518,"end":31526},{"type":"TextQuoteSelector","exact":"Figure 4","prefix":"l Open-Domain Question Answering","suffix":". Answering accuracy and retriev"}]}]}
>```
>%%
>*%%PREFIX%%l Open-Domain Question Answering%%HIGHLIGHT%% ==Figure 4== %%POSTFIX%%. Answering accuracy and retriev*
>%%LINK%%[[#^btr1thghain|show annotation]]
>%%COMMENT%%
>BIGG---can definitely get some use out of this
>%%TAGS%%
>
^btr1thghain


>%%
>```annotation-json
>{"created":"2023-08-06T15:07:56.627Z","updated":"2023-08-06T15:07:56.627Z","document":{"title":"lievin23a.pdf","link":[{"href":"urn:x-pdf:ed2b119e8f77e065d14f1357b2c13c63"},{"href":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf"}],"documentFingerprint":"ed2b119e8f77e065d14f1357b2c13c63"},"uri":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf","target":[{"source":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf","selector":[{"type":"TextPositionSelector","start":31944,"end":32043},{"type":"TextQuoteSelector","exact":"Higher P values leads to smaller effective sample sizes, slowerlearning but better end performances","prefix":" effective sample size is 4096).","suffix":".and answers (q,a⋆), this transl"}]}]}
>```
>%%
>*%%PREFIX%%effective sample size is 4096).%%HIGHLIGHT%% ==Higher P values leads to smaller effective sample sizes, slowerlearning but better end performances== %%POSTFIX%%.and answers (q,a⋆), this transl*
>%%LINK%%[[#^wagf74ukqas|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^wagf74ukqas


>%%
>```annotation-json
>{"created":"2023-08-06T15:08:52.952Z","text":"ooooh","updated":"2023-08-06T15:08:52.952Z","document":{"title":"lievin23a.pdf","link":[{"href":"urn:x-pdf:ed2b119e8f77e065d14f1357b2c13c63"},{"href":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf"}],"documentFingerprint":"ed2b119e8f77e065d14f1357b2c13c63"},"uri":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf","target":[{"source":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf","selector":[{"type":"TextPositionSelector","start":36171,"end":36411},{"type":"TextQuoteSelector","exact":"While the VODobjective is consistent w.r.t. the RVB (Appendix B), its re-liance on the self-normalization introduces a deviation fromthe strict guarantee of being a lower bound for the marginallog-likelihood, which is provided by the IW-RVB","prefix":"tion error remains unaddressed. ","suffix":". Nonethe-less, the utilization "}]}]}
>```
>%%
>*%%PREFIX%%tion error remains unaddressed.%%HIGHLIGHT%% ==While the VODobjective is consistent w.r.t. the RVB (Appendix B), its re-liance on the self-normalization introduces a deviation fromthe strict guarantee of being a lower bound for the marginallog-likelihood, which is provided by the IW-RVB== %%POSTFIX%%. Nonethe-less, the utilization*
>%%LINK%%[[#^6ejz569tj1j|show annotation]]
>%%COMMENT%%
>ooooh
>%%TAGS%%
>
^6ejz569tj1j


>%%
>```annotation-json
>{"created":"2023-08-06T16:57:58.149Z","text":"*Could* do an explanatory slide in the prez appendix, but the following sentence or something like it will suffice:\n\nPriority sampling is basically a form of importance sampling but where you only compute your sum over $K < N$ of your $N$ weights ","updated":"2023-08-06T16:57:58.149Z","document":{"title":"lievin23a.pdf","link":[{"href":"urn:x-pdf:ed2b119e8f77e065d14f1357b2c13c63"},{"href":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf"}],"documentFingerprint":"ed2b119e8f77e065d14f1357b2c13c63"},"uri":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf","target":[{"source":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf","selector":[{"type":"TextPositionSelector","start":61541,"end":61558},{"type":"TextQuoteSelector","exact":"Priority sampling","prefix":"pen-Domain Question AnsweringA. ","suffix":"Figure 5. Estimation of the weig"}]}]}
>```
>%%
>*%%PREFIX%%pen-Domain Question AnsweringA.%%HIGHLIGHT%% ==Priority sampling== %%POSTFIX%%Figure 5. Estimation of the weig*
>%%LINK%%[[#^kfwwhsylc7l|show annotation]]
>%%COMMENT%%
>*Could* do an explanatory slide in the prez appendix, but the following sentence or something like it will suffice:
>
>Priority sampling is basically a form of importance sampling but where you only compute your sum over $K < N$ of your $N$ weights 
>%%TAGS%%
>
^kfwwhsylc7l


>%%
>```annotation-json
>{"created":"2023-08-06T17:07:27.228Z","text":"Proposal $r_\\phi (\\mathbf{d}|\\mathbf{a}, \\mathbf{q})$ is like the retriever $p_\\theta (\\mathbf{d}|\\mathbf{q})$ BUT also receives the corresponding (maybe correct, maybe incorrect) answer","updated":"2023-08-06T17:07:27.228Z","document":{"title":"lievin23a.pdf","link":[{"href":"urn:x-pdf:ed2b119e8f77e065d14f1357b2c13c63"},{"href":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf"}],"documentFingerprint":"ed2b119e8f77e065d14f1357b2c13c63"},"uri":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf"}
>```
>%%
>*%%PREFIX%%%%HIGHLIGHT%% ==== %%POSTFIX%%*
>%%LINK%%[[#^6ozjq10eyt5|show annotation]]
>%%COMMENT%%
>Proposal $r_\phi (\mathbf{d}|\mathbf{a}, \mathbf{q})$ is like the retriever $p_\theta (\mathbf{d}|\mathbf{q})$ BUT also receives the corresponding (maybe correct, maybe incorrect) answer
>%%TAGS%%
>
^6ozjq10eyt5


>%%
>```annotation-json
>{"created":"2023-08-06T17:15:46.992Z","updated":"2023-08-06T17:15:46.992Z","document":{"title":"lievin23a.pdf","link":[{"href":"urn:x-pdf:ed2b119e8f77e065d14f1357b2c13c63"},{"href":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf"}],"documentFingerprint":"ed2b119e8f77e065d14f1357b2c13c63"},"uri":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf","target":[{"source":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf","selector":[{"type":"TextPositionSelector","start":67319,"end":67733},{"type":"TextQuoteSelector","exact":"The VOD objective is a self-normalized importance sampling estimate of the RVB, whereas the IW-RVB is a standardimportance sampling. The VOD objective only differs from the IW-RVB because (i) VOD relies on self-normalized prioritysampling eq. (28a), (ii) the normalizing constant ZθZ−1φ in the expression of the importance weight wθ,φ(a,q,d) isestimated with a self-normalized priority sampling estimate eq. (28b).","prefix":"wθ,φ(q,a,d)] = LELBO(a,q) . (22)","suffix":"B.3. Derivation of the VOD objec"}]}]}
>```
>%%
>*%%PREFIX%%wθ,φ(q,a,d)] = LELBO(a,q) . (22)%%HIGHLIGHT%% ==The VOD objective is a self-normalized importance sampling estimate of the RVB, whereas the IW-RVB is a standardimportance sampling. The VOD objective only differs from the IW-RVB because (i) VOD relies on self-normalized prioritysampling eq. (28a), (ii) the normalizing constant ZθZ−1φ in the expression of the importance weight wθ,φ(a,q,d) isestimated with a self-normalized priority sampling estimate eq. (28b).== %%POSTFIX%%B.3. Derivation of the VOD objec*
>%%LINK%%[[#^nzfkrckvcu|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^nzfkrckvcu


>%%
>```annotation-json
>{"created":"2023-08-06T17:57:03.590Z","updated":"2023-08-06T17:57:03.590Z","document":{"title":"lievin23a.pdf","link":[{"href":"urn:x-pdf:ed2b119e8f77e065d14f1357b2c13c63"},{"href":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf"}],"documentFingerprint":"ed2b119e8f77e065d14f1357b2c13c63"},"uri":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf","target":[{"source":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf","selector":[{"type":"TextPositionSelector","start":9248,"end":9513},{"type":"TextQuoteSelector","exact":"For α = 0, the RVB aligns with the marginal log-likelihoodindependently of the choice of the approximate posterior.However, when the importance weight wθ,φ(q,a,d) suffersfrom high variance, so does the Monte Carlo estimate of themarginal likelihood and its gradient","prefix":"e early optimization challenges.","suffix":".5For α = 1, the RVB matches the"}]}]}
>```
>%%
>*%%PREFIX%%e early optimization challenges.%%HIGHLIGHT%% ==For α = 0, the RVB aligns with the marginal log-likelihoodindependently of the choice of the approximate posterior.However, when the importance weight wθ,φ(q,a,d) suffersfrom high variance, so does the Monte Carlo estimate of themarginal likelihood and its gradient== %%POSTFIX%%.5For α = 1, the RVB matches the*
>%%LINK%%[[#^m9hq5is61p|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^m9hq5is61p


>%%
>```annotation-json
>{"created":"2023-08-06T18:31:35.181Z","text":"We're sampling our documents (via priority sampling) using the approx posterior (the \"fixed retriever\") $r_\\phi (\\mathbf{d}|\\mathbf{a}, \\mathbf{q})$ which is a hybrid of checkpoint values of $f_\\theta$ at each $T$ iterations and using the BM25 scores.","updated":"2023-08-06T18:31:35.181Z","document":{"title":"lievin23a.pdf","link":[{"href":"urn:x-pdf:ed2b119e8f77e065d14f1357b2c13c63"},{"href":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf"}],"documentFingerprint":"ed2b119e8f77e065d14f1357b2c13c63"},"uri":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf"}
>```
>%%
>*%%PREFIX%%%%HIGHLIGHT%% ==== %%POSTFIX%%*
>%%LINK%%[[#^pppjm10qg0k|show annotation]]
>%%COMMENT%%
>We're sampling our documents (via priority sampling) using the approx posterior (the "fixed retriever") $r_\phi (\mathbf{d}|\mathbf{a}, \mathbf{q})$ which is a hybrid of checkpoint values of $f_\theta$ at each $T$ iterations and using the BM25 scores.
>%%TAGS%%
>
^pppjm10qg0k


>%%
>```annotation-json
>{"created":"2023-08-06T18:34:06.871Z","text":"SOOO: at each iteration they only compute gradient updates w.r.t. $\\theta$ and then only update $\\phi$ every $T$ iterations!","updated":"2023-08-06T18:34:06.871Z","document":{"title":"lievin23a.pdf","link":[{"href":"urn:x-pdf:ed2b119e8f77e065d14f1357b2c13c63"},{"href":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf"}],"documentFingerprint":"ed2b119e8f77e065d14f1357b2c13c63"},"uri":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf"}
>```
>%%
>*%%PREFIX%%%%HIGHLIGHT%% ==== %%POSTFIX%%*
>%%LINK%%[[#^fbq4q4bpl3g|show annotation]]
>%%COMMENT%%
>SOOO: at each iteration they only compute gradient updates w.r.t. $\theta$ and then only update $\phi$ every $T$ iterations!
>%%TAGS%%
>
^fbq4q4bpl3g


>%%
>```annotation-json
>{"created":"2023-08-06T18:34:50.354Z","text":"At the start of each set of $T$ iterations, we use the approx posterior scoring function $f_\\phi$ to score each document \n$$f_\\phi(\\mathbf{d}_1), ... f_\\phi(\\mathbf{d_K})$$\n\nAt each training iteration, they have $M$ copies of a single question, each concatenated w/ one of the $M$ multiple-choice answers. \n\nThey feed these into $f_\\theta$","updated":"2023-08-06T18:34:50.354Z","document":{"title":"lievin23a.pdf","link":[{"href":"urn:x-pdf:ed2b119e8f77e065d14f1357b2c13c63"},{"href":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf"}],"documentFingerprint":"ed2b119e8f77e065d14f1357b2c13c63"},"uri":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf"}
>```
>%%
>*%%PREFIX%%%%HIGHLIGHT%% ==== %%POSTFIX%%*
>%%LINK%%[[#^hx78l2hflxs|show annotation]]
>%%COMMENT%%
>At the start of each set of $T$ iterations, we use the approx posterior scoring function $f_\phi$ to score each document 
>$$f_\phi(\mathbf{d}_1), ... f_\phi(\mathbf{d_K})$$
>
>At each training iteration, they have $M$ copies of a single question, each concatenated w/ one of the $M$ multiple-choice answers. 
>
>They feed these into $f_\theta$
>%%TAGS%%
>
^hx78l2hflxs


>%%
>```annotation-json
>{"created":"2023-08-06T18:48:59.574Z","text":"I think that this could give some good insight into what is actually going on, i.e. how are the probabilities **actually** represented/computed --- what is BERT doing? and what is BERT not doing?","updated":"2023-08-06T18:48:59.574Z","document":{"title":"lievin23a.pdf","link":[{"href":"urn:x-pdf:ed2b119e8f77e065d14f1357b2c13c63"},{"href":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf"}],"documentFingerprint":"ed2b119e8f77e065d14f1357b2c13c63"},"uri":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf","target":[{"source":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf","selector":[{"type":"TextPositionSelector","start":65866,"end":65886},{"type":"TextQuoteSelector","exact":"B.1. Complexity O(K)","prefix":"-RVB with probability 1 as K →∞.","suffix":"Evaluating the VOD objective eq."}]}]}
>```
>%%
>*%%PREFIX%%-RVB with probability 1 as K →∞.%%HIGHLIGHT%% ==B.1. Complexity O(K)== %%POSTFIX%%Evaluating the VOD objective eq.*
>%%LINK%%[[#^1do952v15ni|show annotation]]
>%%COMMENT%%
>I think that this could give some good insight into what is actually going on, i.e. how are the probabilities **actually** represented/computed --- what is BERT doing? and what is BERT not doing?
>%%TAGS%%
>
^1do952v15ni


>%%
>```annotation-json
>{"created":"2023-08-07T08:56:48.309Z","updated":"2023-08-07T08:56:48.309Z","document":{"title":"lievin23a.pdf","link":[{"href":"urn:x-pdf:ed2b119e8f77e065d14f1357b2c13c63"},{"href":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf"}],"documentFingerprint":"ed2b119e8f77e065d14f1357b2c13c63"},"uri":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf","target":[{"source":"https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf","selector":[{"type":"TextPositionSelector","start":24022,"end":24144},{"type":"TextQuoteSelector","exact":"for each question-answer pair qj, we retrieve the set of top-P documents Tφand cache the set of values {fφ(aj,q,d) |d ∈Tφ}","prefix":"At the beginning of each round, ","suffix":", exceptfor the first period whe"}]}]}
>```
>%%
>*%%PREFIX%%At the beginning of each round,%%HIGHLIGHT%% ==for each question-answer pair qj, we retrieve the set of top-P documents Tφand cache the set of values {fφ(aj,q,d) |d ∈Tφ}== %%POSTFIX%%, exceptfor the first period whe*
>%%LINK%%[[#^2vy6s3m3yo3|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^2vy6s3m3yo3

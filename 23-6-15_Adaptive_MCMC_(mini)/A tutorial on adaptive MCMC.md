annotation-target:: https://people.eecs.berkeley.edu/~jordan/sail/readings/andrieu-thoms.pdf

>%%
>```annotation-json
>{"created":"2023-06-09T13:01:41.759Z","updated":"2023-06-09T13:01:41.759Z","document":{"title":"","link":[{"href":"urn:x-pdf:75390582e763e25801cf854bb6717de1"},{"href":"https://people.eecs.berkeley.edu/~jordan/sail/readings/andrieu-thoms.pdf"}],"documentFingerprint":"75390582e763e25801cf854bb6717de1"},"uri":"https://people.eecs.berkeley.edu/~jordan/sail/readings/andrieu-thoms.pdf","target":[{"source":"https://people.eecs.berkeley.edu/~jordan/sail/readings/andrieu-thoms.pdf","selector":[{"type":"TextPositionSelector","start":2177,"end":2269},{"type":"TextQuoteSelector","exact":"The main building block of this classof algorithms is the Metropolis-Hastings (MH) algorithm","prefix":"ion of Xito π as π -ergodicity. ","suffix":". Itrequires the definition of a"}]}]}
>```
>%%
>*%%PREFIX%%ion of Xito π as π -ergodicity.%%HIGHLIGHT%% ==The main building block of this classof algorithms is the Metropolis-Hastings (MH) algorithm== %%POSTFIX%%. Itrequires the definition of a*
>%%LINK%%[[#^f2trq17ez0r|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^f2trq17ez0r


>%%
>```annotation-json
>{"created":"2023-06-09T13:02:34.008Z","text":"so proposals are hard to tune","updated":"2023-06-09T13:02:34.008Z","document":{"title":"","link":[{"href":"urn:x-pdf:75390582e763e25801cf854bb6717de1"},{"href":"https://people.eecs.berkeley.edu/~jordan/sail/readings/andrieu-thoms.pdf"}],"documentFingerprint":"75390582e763e25801cf854bb6717de1"},"uri":"https://people.eecs.berkeley.edu/~jordan/sail/readings/andrieu-thoms.pdf","target":[{"source":"https://people.eecs.berkeley.edu/~jordan/sail/readings/andrieu-thoms.pdf","selector":[{"type":"TextPositionSelector","start":3243,"end":3517},{"type":"TextQuoteSelector","exact":"The varianceof the corresponding estimator ˆI θN (f ), which we wish to beas small as possible for the purpose of efficiency, is wellknown to be typically unsatisfactory for values of θ 2 thatare either “too small or too large” in comparison to optimalor suboptimal value(s)","prefix":"kov transition probability Pθ . ","suffix":". In more realistic scenarios, M"}]}]}
>```
>%%
>*%%PREFIX%%kov transition probability Pθ .%%HIGHLIGHT%% ==The varianceof the corresponding estimator ˆI θN (f ), which we wish to beas small as possible for the purpose of efficiency, is wellknown to be typically unsatisfactory for values of θ 2 thatare either “too small or too large” in comparison to optimalor suboptimal value(s)== %%POSTFIX%%. In more realistic scenarios, M*
>%%LINK%%[[#^20d4n8l82gy|show annotation]]
>%%COMMENT%%
>so proposals are hard to tune
>%%TAGS%%
>
^20d4n8l82gy


>%%
>```annotation-json
>{"created":"2023-06-09T13:04:19.672Z","updated":"2023-06-09T13:04:19.672Z","document":{"title":"","link":[{"href":"urn:x-pdf:75390582e763e25801cf854bb6717de1"},{"href":"https://people.eecs.berkeley.edu/~jordan/sail/readings/andrieu-thoms.pdf"}],"documentFingerprint":"75390582e763e25801cf854bb6717de1"},"uri":"https://people.eecs.berkeley.edu/~jordan/sail/readings/andrieu-thoms.pdf","target":[{"source":"https://people.eecs.berkeley.edu/~jordan/sail/readings/andrieu-thoms.pdf","selector":[{"type":"TextPositionSelector","start":3548,"end":3797},{"type":"TextQuoteSelector","exact":"MCMCalgorithms are in general combinations of several MH up-dates {Pk,θ , k = 1, . . . , n, θ  ∈ \u0005} for some set \u0005, with eachhaving its own parametrised proposal distribution qk,θ fork = 1, . . . , n  and sharing π as common invariant distribu-tion.","prefix":"). In more realistic scenarios, ","suffix":" These transition probabilities "}]}]}
>```
>%%
>*%%PREFIX%%). In more realistic scenarios,%%HIGHLIGHT%% ==MCMCalgorithms are in general combinations of several MH up-dates {Pk,θ , k = 1, . . . , n, θ  ∈ } for some set , with eachhaving its own parametrised proposal distribution qk,θ fork = 1, . . . , n  and sharing π as common invariant distribu-tion.== %%POSTFIX%%These transition probabilities*
>%%LINK%%[[#^uwvlhrv879|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^uwvlhrv879



>%%
>```annotation-json
>{"created":"2023-06-09T13:05:19.737Z","updated":"2023-06-09T13:05:19.737Z","document":{"title":"","link":[{"href":"urn:x-pdf:75390582e763e25801cf854bb6717de1"},{"href":"https://people.eecs.berkeley.edu/~jordan/sail/readings/andrieu-thoms.pdf"}],"documentFingerprint":"75390582e763e25801cf854bb6717de1"},"uri":"https://people.eecs.berkeley.edu/~jordan/sail/readings/andrieu-thoms.pdf","target":[{"source":"https://people.eecs.berkeley.edu/~jordan/sail/readings/andrieu-thoms.pdf","selector":[{"type":"TextPositionSelector","start":4016,"end":4046},{"type":"TextQuoteSelector","exact":"mixture ofdifferent strategies","prefix":" for example take the form of a ","suffix":", i.e.Pθ (x, dy) =n∑k=1wk (θ )Pk"}]}]}
>```
>%%
>*%%PREFIX%%for example take the form of a%%HIGHLIGHT%% ==mixture ofdifferent strategies== %%POSTFIX%%, i.e.Pθ (x, dy) =n∑k=1wk (θ )Pk*
>%%LINK%%[[#^wnr8aj1fnj|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^wnr8aj1fnj


>%%
>```annotation-json
>{"created":"2023-06-09T13:05:27.479Z","updated":"2023-06-09T13:05:27.479Z","document":{"title":"","link":[{"href":"urn:x-pdf:75390582e763e25801cf854bb6717de1"},{"href":"https://people.eecs.berkeley.edu/~jordan/sail/readings/andrieu-thoms.pdf"}],"documentFingerprint":"75390582e763e25801cf854bb6717de1"},"uri":"https://people.eecs.berkeley.edu/~jordan/sail/readings/andrieu-thoms.pdf","target":[{"source":"https://people.eecs.berkeley.edu/~jordan/sail/readings/andrieu-thoms.pdf","selector":[{"type":"TextPositionSelector","start":4154,"end":4203},{"type":"TextQuoteSelector","exact":"also, for example, take the form of combinations ","prefix":"k (θ ) = 1, wk (θ ) ≥ 0, but can","suffix":"(i.e. prod-ucts of transition ma"}]}]}
>```
>%%
>*%%PREFIX%%k (θ ) = 1, wk (θ ) ≥ 0, but can%%HIGHLIGHT%% ==also, for example, take the form of combinations== %%POSTFIX%%(i.e. prod-ucts of transition ma*
>%%LINK%%[[#^zwp56vsiye|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^zwp56vsiye


>%%
>```annotation-json
>{"created":"2023-06-09T13:05:48.162Z","updated":"2023-06-09T13:05:48.162Z","document":{"title":"","link":[{"href":"urn:x-pdf:75390582e763e25801cf854bb6717de1"},{"href":"https://people.eecs.berkeley.edu/~jordan/sail/readings/andrieu-thoms.pdf"}],"documentFingerprint":"75390582e763e25801cf854bb6717de1"},"uri":"https://people.eecs.berkeley.edu/~jordan/sail/readings/andrieu-thoms.pdf","target":[{"source":"https://people.eecs.berkeley.edu/~jordan/sail/readings/andrieu-thoms.pdf","selector":[{"type":"TextPositionSelector","start":6181,"end":6234},{"type":"TextQuoteSelector","exact":"denote by θ ∗ a genericoptimal value for our criteria","prefix":"on examples in Sect. 6. We will ","suffix":", which is always assumed toexis"}]}]}
>```
>%%
>*%%PREFIX%%on examples in Sect. 6. We will%%HIGHLIGHT%% ==denote by θ ∗ a genericoptimal value for our criteria== %%POSTFIX%%, which is always assumed toexis*
>%%LINK%%[[#^20etgrnyl4n|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^20etgrnyl4n


>%%
>```annotation-json
>{"text":"So use your (possibly random) mappings \n$$ \\theta_i : \\Theta \\times \\mathbf{X}^{i+1} \\to \\Theta $$\nto update your param $\\theta_i \\in \\Theta$ at each iteration based on all of the previously generated samples.\n\nThis means that each param value is only used to generate one sample (unless one param value gets mapped to more than once over the course of the iterations), but presumably, we can evaluate its performance using information from the past samples too with clever mappings.","target":[{"source":"https://people.eecs.berkeley.edu/~jordan/sail/readings/andrieu-thoms.pdf","selector":[{"type":"TextPositionSelector","start":7362,"end":7409},{"type":"TextQuoteSelector","exact":"Algorithm 1 Controlled Markov chain Monte Carlo","prefix":"rolled MCMC proceeds as follows:","suffix":"• Sample initial values θ0, X 0"}]}],"created":"2023-06-09T13:06:32.288Z","updated":"2023-06-09T13:06:32.288Z","document":{"title":"","link":[{"href":"urn:x-pdf:75390582e763e25801cf854bb6717de1"},{"href":"https://people.eecs.berkeley.edu/~jordan/sail/readings/andrieu-thoms.pdf"}],"documentFingerprint":"75390582e763e25801cf854bb6717de1"},"uri":"https://people.eecs.berkeley.edu/~jordan/sail/readings/andrieu-thoms.pdf"}
>```
>%%
>*%%PREFIX%%rolled MCMC proceeds as follows:%%HIGHLIGHT%% ==Algorithm 1 Controlled Markov chain Monte Carlo== %%POSTFIX%%• Sample initial values θ0, X 0*
>%%LINK%%[[#^xorvloolgan|show annotation]]
>%%COMMENT%%
>So use your (possibly random) mappings 
>$$ \theta_i : \Theta \times \mathbf{X}^{i+1} \to \Theta $$
>to update your param $\theta_i \in \Theta$ at each iteration based on all of the previously generated samples.
>
>This means that each param value is only used to generate one sample (unless one param value gets mapped to more than once over the course of the iterations), but presumably, we can evaluate its performance using information from the past samples too with clever mappings.
>%%TAGS%%
>
^xorvloolgan


>%%
>```annotation-json
>{"text":"for root-finding of functions that we can only observe noisily\n\na recursive algorithm applying updates with decreasing step sizes\n\nconverges (w/ prob 1 under certain constraints) to true optimal/root $\\theta*$","target":[{"source":"https://people.eecs.berkeley.edu/~jordan/sail/readings/andrieu-thoms.pdf","selector":[{"type":"TextPositionSelector","start":7815,"end":7835},{"type":"TextQuoteSelector","exact":"Robbins-Monro update","prefix":"MC algorithms, whichrely on the","suffix":"and more generally onthe stocha"}]}],"created":"2023-06-09T13:14:36.838Z","updated":"2023-06-09T13:14:36.838Z","document":{"title":"","link":[{"href":"urn:x-pdf:75390582e763e25801cf854bb6717de1"},{"href":"https://people.eecs.berkeley.edu/~jordan/sail/readings/andrieu-thoms.pdf"}],"documentFingerprint":"75390582e763e25801cf854bb6717de1"},"uri":"https://people.eecs.berkeley.edu/~jordan/sail/readings/andrieu-thoms.pdf"}
>```
>%%
>*%%PREFIX%%MC algorithms, whichrely on the%%HIGHLIGHT%% ==Robbins-Monro update== %%POSTFIX%%and more generally onthe stocha*
>%%LINK%%[[#^464va816tp6|show annotation]]
>%%COMMENT%%
>for root-finding of functions that we can only observe noisily
>
>a recursive algorithm applying updates with decreasing step sizes
>
>converges (w/ prob 1 under certain constraints) to true optimal/root $\theta*$
>%%TAGS%%
>
^464va816tp6


>%%
>```annotation-json
>{"created":"2023-06-09T13:19:05.025Z","text":"!! bad","updated":"2023-06-09T13:19:05.025Z","document":{"title":"","link":[{"href":"urn:x-pdf:75390582e763e25801cf854bb6717de1"},{"href":"https://people.eecs.berkeley.edu/~jordan/sail/readings/andrieu-thoms.pdf"}],"documentFingerprint":"75390582e763e25801cf854bb6717de1"},"uri":"https://people.eecs.berkeley.edu/~jordan/sail/readings/andrieu-thoms.pdf","target":[{"source":"https://people.eecs.berkeley.edu/~jordan/sail/readings/andrieu-thoms.pdf","selector":[{"type":"TextPositionSelector","start":8480,"end":8608},{"type":"TextQuoteSelector","exact":"In particular algorithms ofthis type will in most cases lead to the loss of π as an invari-ant distribution of the process {Xi }","prefix":"yproperties of MCMC algorithms. ","suffix":", which intuitively shouldbe the"}]}]}
>```
>%%
>*%%PREFIX%%yproperties of MCMC algorithms.%%HIGHLIGHT%% ==In particular algorithms ofthis type will in most cases lead to the loss of π as an invari-ant distribution of the process {Xi }== %%POSTFIX%%, which intuitively shouldbe the*
>%%LINK%%[[#^ai2dce3zfu|show annotation]]
>%%COMMENT%%
>!! bad
>%%TAGS%%
>
^ai2dce3zfu


>%%
>```annotation-json
>{"created":"2023-06-09T13:20:47.586Z","text":"!! bad also\n","updated":"2023-06-09T13:20:47.586Z","document":{"title":"","link":[{"href":"urn:x-pdf:75390582e763e25801cf854bb6717de1"},{"href":"https://people.eecs.berkeley.edu/~jordan/sail/readings/andrieu-thoms.pdf"}],"documentFingerprint":"75390582e763e25801cf854bb6717de1"},"uri":"https://people.eecs.berkeley.edu/~jordan/sail/readings/andrieu-thoms.pdf","target":[{"source":"https://people.eecs.berkeley.edu/~jordan/sail/readings/andrieu-thoms.pdf","selector":[{"type":"TextPositionSelector","start":8721,"end":8867},{"type":"TextQuoteSelector","exact":"Note also that when notcarefully designed such controlled MCMC can lead to tran-sient processes or processes such that ˆIN (f ) is not consis-tent","prefix":" lead to consistent estimators. ","suffix":". Studying the convergence prope"}]}]}
>```
>%%
>*%%PREFIX%%lead to consistent estimators.%%HIGHLIGHT%% ==Note also that when notcarefully designed such controlled MCMC can lead to tran-sient processes or processes such that ˆIN (f ) is not consis-tent== %%POSTFIX%%. Studying the convergence prope*
>%%LINK%%[[#^kw5zn8xnwl|show annotation]]
>%%COMMENT%%
>!! bad also
>
>%%TAGS%%
>
^kw5zn8xnwl


>%%
>```annotation-json
>{"created":"2023-06-09T13:22:00.426Z","text":"sounds good but they go on to say that usually the \"evidence\" requires knowledge of \\(\\pi\\) which we have to approximate via MCMC anyway... \n\nso a bit of a circular argument (?) \n\nwould be better to have some solid results about theta's convergence (which is what the authors say they'll provide lateron)","updated":"2023-06-09T13:22:00.426Z","document":{"title":"","link":[{"href":"urn:x-pdf:75390582e763e25801cf854bb6717de1"},{"href":"https://people.eecs.berkeley.edu/~jordan/sail/readings/andrieu-thoms.pdf"}],"documentFingerprint":"75390582e763e25801cf854bb6717de1"},"uri":"https://people.eecs.berkeley.edu/~jordan/sail/readings/andrieu-thoms.pdf","target":[{"source":"https://people.eecs.berkeley.edu/~jordan/sail/readings/andrieu-thoms.pdf","selector":[{"type":"TextPositionSelector","start":9022,"end":9279},{"type":"TextQuoteSelector","exact":"it is often argued thatone might simply stop adaptation once we have enough evi-dence that {θi } has reached a satisfactory optimal or subop-timal value of θ and then simply use samples produced by astandard MCMC algorithm using such a fixed good value  ̃θ ","prefix":" in the present context. Indeed ","suffix":".No new theory should then be re"}]}]}
>```
>%%
>*%%PREFIX%%in the present context. Indeed%%HIGHLIGHT%% ==it is often argued thatone might simply stop adaptation once we have enough evi-dence that {θi } has reached a satisfactory optimal or subop-timal value of θ and then simply use samples produced by astandard MCMC algorithm using such a fixed good value  ̃θ== %%POSTFIX%%.No new theory should then be re*
>%%LINK%%[[#^ipmpokrhnv|show annotation]]
>%%COMMENT%%
>sounds good but they go on to say that usually the "evidence" requires knowledge of \(\pi\) which we have to approximate via MCMC anyway... 
>
>so a bit of a circular argument (?) 
>
>would be better to have some solid results about theta's convergence (which is what the authors say they'll provide lateron)
>%%TAGS%%
>
^ipmpokrhnv


>%%
>```annotation-json
>{"created":"2023-06-09T13:24:33.216Z","text":"ol' reliable","updated":"2023-06-09T13:24:33.216Z","document":{"title":"","link":[{"href":"urn:x-pdf:75390582e763e25801cf854bb6717de1"},{"href":"https://people.eecs.berkeley.edu/~jordan/sail/readings/andrieu-thoms.pdf"}],"documentFingerprint":"75390582e763e25801cf854bb6717de1"},"uri":"https://people.eecs.berkeley.edu/~jordan/sail/readings/andrieu-thoms.pdf","target":[{"source":"https://people.eecs.berkeley.edu/~jordan/sail/readings/andrieu-thoms.pdf","selector":[{"type":"TextPositionSelector","start":2917,"end":2976},{"type":"TextQuoteSelector","exact":"normal symmetric random walk Metropo-lis algorithm (N-SRWM)","prefix":"he toy case wherenx = 1 and the ","suffix":" is used to produce transitions,"}]}]}
>```
>%%
>*%%PREFIX%%he toy case wherenx = 1 and the%%HIGHLIGHT%% ==normal symmetric random walk Metropo-lis algorithm (N-SRWM)== %%POSTFIX%%is used to produce transitions,*
>%%LINK%%[[#^qak4coimcx|show annotation]]
>%%COMMENT%%
>ol' reliable
>%%TAGS%%
>
^qak4coimcx


>%%
>```annotation-json
>{"created":"2023-06-09T13:35:34.326Z","text":"essentially what they dissed in the prev paragraph, but this time they're (presumably) being clever about how/when to set \\(\\tau\\)","updated":"2023-06-09T13:35:34.326Z","document":{"title":"","link":[{"href":"urn:x-pdf:75390582e763e25801cf854bb6717de1"},{"href":"https://people.eecs.berkeley.edu/~jordan/sail/readings/andrieu-thoms.pdf"}],"documentFingerprint":"75390582e763e25801cf854bb6717de1"},"uri":"https://people.eecs.berkeley.edu/~jordan/sail/readings/andrieu-thoms.pdf","target":[{"source":"https://people.eecs.berkeley.edu/~jordan/sail/readings/andrieu-thoms.pdf","selector":[{"type":"TextPositionSelector","start":10371,"end":10605},{"type":"TextQuoteSelector","exact":"users wary of the perturbation to ergodic-ity brought by adaptation might naturally choose to “freeze”{θi } to a value θτ beyond an iteration τ and consider onlysamples produced by the induced Markov chain for their in-ference problem","prefix":"etical develop-ments. Note that ","suffix":". A stopping rule is described i"}]}]}
>```
>%%
>*%%PREFIX%%etical develop-ments. Note that%%HIGHLIGHT%% ==users wary of the perturbation to ergodic-ity brought by adaptation might naturally choose to “freeze”{θi } to a value θτ beyond an iteration τ and consider onlysamples produced by the induced Markov chain for their in-ference problem== %%POSTFIX%%. A stopping rule is described i*
>%%LINK%%[[#^lfjjjq229ca|show annotation]]
>%%COMMENT%%
>essentially what they dissed in the prev paragraph, but this time they're (presumably) being clever about how/when to set \(\tau\)
>%%TAGS%%
>
^lfjjjq229ca


>%%
>```annotation-json
>{"created":"2023-06-09T13:36:47.910Z","text":"big if true\n","updated":"2023-06-09T13:36:47.910Z","document":{"title":"","link":[{"href":"urn:x-pdf:75390582e763e25801cf854bb6717de1"},{"href":"https://people.eecs.berkeley.edu/~jordan/sail/readings/andrieu-thoms.pdf"}],"documentFingerprint":"75390582e763e25801cf854bb6717de1"},"uri":"https://people.eecs.berkeley.edu/~jordan/sail/readings/andrieu-thoms.pdf","target":[{"source":"https://people.eecs.berkeley.edu/~jordan/sail/readings/andrieu-thoms.pdf","selector":[{"type":"TextPositionSelector","start":10663,"end":10732},{"type":"TextQuoteSelector","exact":"we shall see it is possible to run the two proce-dures simultaneously","prefix":"ibed in Sect. 4.2.2.In fact, as ","suffix":".Finally, whereas optimising an "}]}]}
>```
>%%
>*%%PREFIX%%ibed in Sect. 4.2.2.In fact, as%%HIGHLIGHT%% ==we shall see it is possible to run the two proce-dures simultaneously== %%POSTFIX%%.Finally, whereas optimising an*
>%%LINK%%[[#^0wvwz0b2pi19|show annotation]]
>%%COMMENT%%
>big if true
>
>%%TAGS%%
>
^0wvwz0b2pi19


>%%
>```annotation-json
>{"created":"2023-06-09T13:41:18.042Z","updated":"2023-06-09T13:41:18.042Z","document":{"title":"","link":[{"href":"urn:x-pdf:75390582e763e25801cf854bb6717de1"},{"href":"https://people.eecs.berkeley.edu/~jordan/sail/readings/andrieu-thoms.pdf"}],"documentFingerprint":"75390582e763e25801cf854bb6717de1"},"uri":"https://people.eecs.berkeley.edu/~jordan/sail/readings/andrieu-thoms.pdf","target":[{"source":"https://people.eecs.berkeley.edu/~jordan/sail/readings/andrieu-thoms.pdf","selector":[{"type":"TextPositionSelector","start":12514,"end":12609},{"type":"TextQuoteSelector","exact":"vanish-ing adaptation (a term made more precise later) might pre-serve asymptotic π -ergodicity","prefix":"ty, these examples suggest that ","suffix":". We then finish this sectionby "}]}]}
>```
>%%
>*%%PREFIX%%ty, these examples suggest that%%HIGHLIGHT%% ==vanish-ing adaptation (a term made more precise later) might pre-serve asymptotic π -ergodicity== %%POSTFIX%%. We then finish this sectionby*
>%%LINK%%[[#^ux2y220n35p|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^ux2y220n35p


>%%
>```annotation-json
>{"created":"2023-06-09T14:08:09.877Z","updated":"2023-06-09T14:08:09.877Z","document":{"title":"","link":[{"href":"urn:x-pdf:75390582e763e25801cf854bb6717de1"},{"href":"https://people.eecs.berkeley.edu/~jordan/sail/readings/andrieu-thoms.pdf"}],"documentFingerprint":"75390582e763e25801cf854bb6717de1"},"uri":"https://people.eecs.berkeley.edu/~jordan/sail/readings/andrieu-thoms.pdf","target":[{"source":"https://people.eecs.berkeley.edu/~jordan/sail/readings/andrieu-thoms.pdf","selector":[{"type":"TextPositionSelector","start":14084,"end":14278},{"type":"TextQuoteSelector","exact":"assume that θ is adapted to the current state in order to sam-ple the next state of the chain, and assume for now thatthis adaptation is a time invariant function of the previousstate of the MC.","prefix":"operator with respect to ν. Now ","suffix":" More precisely assume that for "}]}]}
>```
>%%
>*%%PREFIX%%operator with respect to ν. Now%%HIGHLIGHT%% ==assume that θ is adapted to the current state in order to sam-ple the next state of the chain, and assume for now thatthis adaptation is a time invariant function of the previousstate of the MC.== %%POSTFIX%%More precisely assume that for*
>%%LINK%%[[#^7904aka77em|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^7904aka77em


>%%
>```annotation-json
>{"created":"2023-06-12T09:00:39.373Z","updated":"2023-06-12T09:00:39.373Z","document":{"title":"","link":[{"href":"urn:x-pdf:75390582e763e25801cf854bb6717de1"},{"href":"https://people.eecs.berkeley.edu/~jordan/sail/readings/andrieu-thoms.pdf"}],"documentFingerprint":"75390582e763e25801cf854bb6717de1"},"uri":"https://people.eecs.berkeley.edu/~jordan/sail/readings/andrieu-thoms.pdf","target":[{"source":"https://people.eecs.berkeley.edu/~jordan/sail/readings/andrieu-thoms.pdf","selector":[{"type":"TextPositionSelector","start":15323,"end":15580},{"type":"TextQuoteSelector","exact":"ensure that as i → ∞ , |θi (1) − θi (2)| vanishes.Indeed, while {θi (1)} and {θi (2)} are allowed to evolve for-ever (and maybe not converge) the corresponding transitionprobabilities { ˇPi := Pθi (Xi )} have invariant distributions { ˇ πi }convergent to π ","prefix":"and θi (2) at itera-tion i, and ","suffix":". We might hence expect one to r"}]}]}
>```
>%%
>*%%PREFIX%%and θi (2) at itera-tion i, and%%HIGHLIGHT%% ==ensure that as i → ∞ , |θi (1) − θi (2)| vanishes.Indeed, while {θi (1)} and {θi (2)} are allowed to evolve for-ever (and maybe not converge) the corresponding transitionprobabilities { ˇPi := Pθi (Xi )} have invariant distributions { ˇ πi }convergent to π== %%POSTFIX%%. We might hence expect one to r*
>%%LINK%%[[#^sqvwnn5u0ws|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^sqvwnn5u0ws


>%%
>```annotation-json
>{"created":"2023-06-12T10:13:35.043Z","text":"so if $X_i = \\pi$ then we'll stay in the stationary distribution, BUT, this does not hold in general.\n\nThe counterexample below constructs a new Markov chain of 2D values $Z_i = (X_i, X_{i-1})$ , the first element of which is shown to not have a stationary marginal distribution equal to $\\pi$.\n\nSO: it is not enough (in general) to merely let $\\theta$ depend on $X_{i-1}$","updated":"2023-06-12T10:13:35.043Z","document":{"title":"","link":[{"href":"urn:x-pdf:75390582e763e25801cf854bb6717de1"},{"href":"https://people.eecs.berkeley.edu/~jordan/sail/readings/andrieu-thoms.pdf"}],"documentFingerprint":"75390582e763e25801cf854bb6717de1"},"uri":"https://people.eecs.berkeley.edu/~jordan/sail/readings/andrieu-thoms.pdf","target":[{"source":"https://people.eecs.berkeley.edu/~jordan/sail/readings/andrieu-thoms.pdf","selector":[{"type":"TextPositionSelector","start":16403,"end":16474},{"type":"TextQuoteSelector","exact":"then Xi+1, X i+2, . . .  are all marginally distributed accord-ing to π","prefix":"1)]= [π(Xi+1 = 1), π(Xi+1 = 2)],","suffix":" . Although this calculation is "}]}]}
>```
>%%
>*%%PREFIX%%1)]= [π(Xi+1 = 1), π(Xi+1 = 2)],%%HIGHLIGHT%% ==then Xi+1, X i+2, . . .  are all marginally distributed accord-ing to π== %%POSTFIX%%. Although this calculation is*
>%%LINK%%[[#^7m6id7ss6z|show annotation]]
>%%COMMENT%%
>so if $X_i = \pi$ then we'll stay in the stationary distribution, BUT, this does not hold in general.
>
>The counterexample below constructs a new Markov chain of 2D values $Z_i = (X_i, X_{i-1})$ , the first element of which is shown to not have a stationary marginal distribution equal to $\pi$.
>
>SO: it is not enough (in general) to merely let $\theta$ depend on $X_{i-1}$
>%%TAGS%%
>
^7m6id7ss6z


>%%
>```annotation-json
>{"created":"2023-06-12T10:41:50.992Z","updated":"2023-06-12T10:41:50.992Z","document":{"title":"","link":[{"href":"urn:x-pdf:75390582e763e25801cf854bb6717de1"},{"href":"https://people.eecs.berkeley.edu/~jordan/sail/readings/andrieu-thoms.pdf"}],"documentFingerprint":"75390582e763e25801cf854bb6717de1"},"uri":"https://people.eecs.berkeley.edu/~jordan/sail/readings/andrieu-thoms.pdf","target":[{"source":"https://people.eecs.berkeley.edu/~jordan/sail/readings/andrieu-thoms.pdf","selector":[{"type":"TextPositionSelector","start":17580,"end":17839},{"type":"TextQuoteSelector","exact":"Let us denote ˇE∗ theexpectation for the process started at some arbitrary θ, x ∈\u0005 × X. This operator is particularly useful to describe theexpectation of ψ(Xi , X i+1, . . .)  for any i ≥ 1 and any func-tion ψ : Xkψ → R, ˇE∗(ψ(Xi , X i+1, . . . , X i+kψ −1))","prefix":"generated by a controlled MCMC. ","suffix":". More precisely it allows one t"}]}]}
>```
>%%
>*%%PREFIX%%generated by a controlled MCMC.%%HIGHLIGHT%% ==Let us denote ˇE∗ theexpectation for the process started at some arbitrary θ, x ∈ × X. This operator is particularly useful to describe theexpectation of ψ(Xi , X i+1, . . .)  for any i ≥ 1 and any func-tion ψ : Xkψ → R, ˇE∗(ψ(Xi , X i+1, . . . , X i+kψ −1))== %%POSTFIX%%. More precisely it allows one t*
>%%LINK%%[[#^3ruk3avfz19|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^3ruk3avfz19


>%%
>```annotation-json
>{"created":"2023-06-12T10:43:08.636Z","text":"this is the expectation of $f(X_{i+1})$ given all previous samples $X_1, \\ldots, X_n$ and initial param $\\theta_0$.","updated":"2023-06-12T10:43:08.636Z","document":{"title":"","link":[{"href":"urn:x-pdf:75390582e763e25801cf854bb6717de1"},{"href":"https://people.eecs.berkeley.edu/~jordan/sail/readings/andrieu-thoms.pdf"}],"documentFingerprint":"75390582e763e25801cf854bb6717de1"},"uri":"https://people.eecs.berkeley.edu/~jordan/sail/readings/andrieu-thoms.pdf","target":[{"source":"https://people.eecs.berkeley.edu/~jordan/sail/readings/andrieu-thoms.pdf","selector":[{"type":"TextPositionSelector","start":19144,"end":19208},{"type":"TextQuoteSelector","exact":"φ(θ0, X 0, . . . , X i ) :=∫XPθi (θ0 ,X0 ,...,Xi )(Xi , dx)f (x)","prefix":"ulties. We will hereafter denote","suffix":",and whenever possible will drop"}]}]}
>```
>%%
>*%%PREFIX%%ulties. We will hereafter denote%%HIGHLIGHT%% ==φ(θ0, X 0, . . . , X i ) :=∫XPθi (θ0 ,X0 ,...,Xi )(Xi , dx)f (x)== %%POSTFIX%%,and whenever possible will drop*
>%%LINK%%[[#^1agk82zbwj4|show annotation]]
>%%COMMENT%%
>this is the expectation of $f(X_{i+1})$ given all previous samples $X_1, \ldots, X_n$ and initial param $\theta_0$.
>%%TAGS%%
>
^1agk82zbwj4


>%%
>```annotation-json
>{"created":"2023-06-12T10:47:44.394Z","text":"very nice standard MCMC result\n\nb/c $\\theta$ never changes, the expectation of a function of our samples is equal to the expectation w.r.t. $\\pi$! (For $i > 0$ big enough that $X_{j} \\sim \\pi$ $\\forall j > i$.)\n\n(Ultimately, this is what MCMC is all about)","updated":"2023-06-12T10:47:44.394Z","document":{"title":"","link":[{"href":"urn:x-pdf:75390582e763e25801cf854bb6717de1"},{"href":"https://people.eecs.berkeley.edu/~jordan/sail/readings/andrieu-thoms.pdf"}],"documentFingerprint":"75390582e763e25801cf854bb6717de1"},"uri":"https://people.eecs.berkeley.edu/~jordan/sail/readings/andrieu-thoms.pdf","target":[{"source":"https://people.eecs.berkeley.edu/~jordan/sail/readings/andrieu-thoms.pdf","selector":[{"type":"TextPositionSelector","start":19830,"end":19986},{"type":"TextQuoteSelector","exact":"a standard MCMC al-gorithm has the well known and fundamental propertyˇE∗(f (Xi+1)) = ˇE∗ (φ(θ, Xi ))= Eπ (φ(θ, X))=∫X×Xπ(dx)Pθ (x, dy)f (y) = Eπ (f (X) ) ,","prefix":" θ ∈ \u0005 and θi = θ for all i ≥ 0 ","suffix":"where the second equality stems "}]}]}
>```
>%%
>*%%PREFIX%%θ ∈  and θi = θ for all i ≥ 0%%HIGHLIGHT%% ==a standard MCMC al-gorithm has the well known and fundamental propertyˇE∗(f (Xi+1)) = ˇE∗ (φ(θ, Xi ))= Eπ (φ(θ, X))=∫X×Xπ(dx)Pθ (x, dy)f (y) = Eπ (f (X) ) ,== %%POSTFIX%%where the second equality stems*
>%%LINK%%[[#^2sd5mxk83w6|show annotation]]
>%%COMMENT%%
>very nice standard MCMC result
>
>b/c $\theta$ never changes, the expectation of a function of our samples is equal to the expectation w.r.t. $\pi$! (For $i > 0$ big enough that $X_{j} \sim \pi$ $\forall j > i$.)
>
>(Ultimately, this is what MCMC is all about)
>%%TAGS%%
>
^2sd5mxk83w6


>%%
>```annotation-json
>{"created":"2023-06-12T10:51:49.667Z","text":"We want the property in the previous note: that after a certain point, the expectation of a function of our samples becomes the expectation of that function over $\\pi$.\n\nBUT WE CAN'T:\n\nThis is b/c in the \"controlled\" (adaptive) MCMC setting we're using the expectation operator $\\v{\\mathbb{E}}_*$ which uses our useful function $\\varphi(\\theta_0, X_0, \\ldots, X_i)$ and in *this* case we've assumed that $\\theta_i$ depends only $X_{i-1}$ so when using a $\\varphi$ that only cares about $\\theta_i$ and $X_i$ we get:\n\n$$\\varphi(\\theta_0, X_0, \\ldots, X_i) = \\varphi(\\theta_i, X_i) = \\varphi(X_{i-1}, X_i)$$\n\nThis introduces a conditioning on $X_i$ (or more generally, some $X in \\mathbf{X}$) when we use the tower rule. Hence, (very sadly) we get that in general the nice standard MCMC result doesn't hold for \"controlled\" (adaptive) MCMC:\n\n$$\\v{\\mathbb{E}}_*(f(X_{i+1})) \n\\neq \n\\v{\\mathbb{E}}_* \\left( \n\\mathbb{E}_\\pi  \\left(\n\\int_\\mathbb{X} P_{\\theta(\\theta_0, X_0, X_{i-1})} (X, d_x{i+1})f(x_{i+1})\n\\right)\n\\right). \n","updated":"2023-06-12T10:51:49.667Z","document":{"title":"","link":[{"href":"urn:x-pdf:75390582e763e25801cf854bb6717de1"},{"href":"https://people.eecs.berkeley.edu/~jordan/sail/readings/andrieu-thoms.pdf"}],"documentFingerprint":"75390582e763e25801cf854bb6717de1"},"uri":"https://people.eecs.berkeley.edu/~jordan/sail/readings/andrieu-thoms.pdf","target":[{"source":"https://people.eecs.berkeley.edu/~jordan/sail/readings/andrieu-thoms.pdf","selector":[{"type":"TextPositionSelector","start":20688,"end":20918},{"type":"TextQuoteSelector","exact":"Now it would be tempting to use the stationarity assumptionin the last expression,Eπ (φ(Xi−1, X) ) =∫X×Xπ(dx)Pθ(Xi−1 )(x, dy)f (y)= Eπ (f (X)).This is however not possible due to the presence of theconditional expectation ˇE∗(·|X)","prefix":"|Xi ))= Eπ(ˇE∗ (φ(Xi−1, X) |X)).","suffix":" (which crucially dependson X) a"}]}]}
>```
>%%
>*%%PREFIX%%|Xi ))= Eπ(ˇE∗ (φ(Xi−1, X) |X)).%%HIGHLIGHT%% ==Now it would be tempting to use the stationarity assumptionin the last expression,Eπ (φ(Xi−1, X) ) =∫X×Xπ(dx)Pθ(Xi−1 )(x, dy)f (y)= Eπ (f (X)).This is however not possible due to the presence of theconditional expectation ˇE∗(·|X)== %%POSTFIX%%(which crucially dependson X) a*
>%%LINK%%[[#^9dfi5k2vxb4|show annotation]]
>%%COMMENT%%
>We want the property in the previous note: that after a certain point, the expectation of a function of our samples becomes the expectation of that function over $\pi$.
>
>BUT WE CAN'T:
>
>This is b/c in the "controlled" (adaptive) MCMC setting we're using the expectation operator $\v{\mathbb{E}}_*$ which uses our useful function $\varphi(\theta_0, X_0, \ldots, X_i)$ and in *this* case we've assumed that $\theta_i$ depends only $X_{i-1}$ so when using a $\varphi$ that only cares about $\theta_i$ and $X_i$ we get:
>
>$$\varphi(\theta_0, X_0, \ldots, X_i) = \varphi(\theta_i, X_i) = \varphi(X_{i-1}, X_i)$$
>
>This introduces a conditioning on $X_i$ (or more generally, some $X in \mathbf{X}$) when we use the tower rule. Hence, (very sadly) we get that in general the nice standard MCMC result doesn't hold for "controlled" (adaptive) MCMC:
>
>$$\v{\mathbb{E}}_*(f(X_{i+1})) 
>\neq 
>\v{\mathbb{E}}_* \left( 
>\mathbb{E}_\pi  \left(
>\int_\mathbb{X} P_{\theta(\theta_0, X_0, X_{i-1})} (X, d_x{i+1})f(x_{i+1})
>\right)
>\right). 
>
>%%TAGS%%
>
^9dfi5k2vxb4


>%%
>```annotation-json
>{"created":"2023-06-12T11:05:53.661Z","updated":"2023-06-12T11:05:53.661Z","document":{"title":"","link":[{"href":"urn:x-pdf:75390582e763e25801cf854bb6717de1"},{"href":"https://people.eecs.berkeley.edu/~jordan/sail/readings/andrieu-thoms.pdf"}],"documentFingerprint":"75390582e763e25801cf854bb6717de1"},"uri":"https://people.eecs.berkeley.edu/~jordan/sail/readings/andrieu-thoms.pdf","target":[{"source":"https://people.eecs.berkeley.edu/~jordan/sail/readings/andrieu-thoms.pdf","selector":[{"type":"TextPositionSelector","start":22667,"end":22931},{"type":"TextQuoteSelector","exact":"whereas π -ergodicity of Pθ is ensured for any θ ∈ \u0005,this property might be lost if the sequence {θi } wanders to-wards “bad” values of θ for which convergence to equilib-rium of the corresponding fixed parameter Markov chainsPθ might take an arbitrarily long time","prefix":" exploit vanishing adapta-tion: ","suffix":".This point is detailed in the n"}]}]}
>```
>%%
>*%%PREFIX%%exploit vanishing adapta-tion:%%HIGHLIGHT%% ==whereas π -ergodicity of Pθ is ensured for any θ ∈ ,this property might be lost if the sequence {θi } wanders to-wards “bad” values of θ for which convergence to equilib-rium of the corresponding fixed parameter Markov chainsPθ might take an arbitrarily long time== %%POSTFIX%%.This point is detailed in the n*
>%%LINK%%[[#^ncj5nxq9xx|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^ncj5nxq9xx


>%%
>```annotation-json
>{"created":"2023-06-12T11:06:27.863Z","updated":"2023-06-12T11:06:27.863Z","document":{"title":"","link":[{"href":"urn:x-pdf:75390582e763e25801cf854bb6717de1"},{"href":"https://people.eecs.berkeley.edu/~jordan/sail/readings/andrieu-thoms.pdf"}],"documentFingerprint":"75390582e763e25801cf854bb6717de1"},"uri":"https://people.eecs.berkeley.edu/~jordan/sail/readings/andrieu-thoms.pdf","target":[{"source":"https://people.eecs.berkeley.edu/~jordan/sail/readings/andrieu-thoms.pdf","selector":[{"type":"TextPositionSelector","start":21216,"end":21352},{"type":"TextQuoteSelector","exact":"Vanishing adaptation seems, intuitively, to offer the pos-sibility to circumvent the problem of the loss of π as in-variant distribution","prefix":"ends to more general situations.","suffix":". However, as illustrated by the"}]}]}
>```
>%%
>*%%PREFIX%%ends to more general situations.%%HIGHLIGHT%% ==Vanishing adaptation seems, intuitively, to offer the pos-sibility to circumvent the problem of the loss of π as in-variant distribution== %%POSTFIX%%. However, as illustrated by the*
>%%LINK%%[[#^vocedbuugwq|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^vocedbuugwq


>%%
>```annotation-json
>{"created":"2023-06-12T12:20:07.751Z","updated":"2023-06-12T12:20:07.751Z","document":{"title":"","link":[{"href":"urn:x-pdf:75390582e763e25801cf854bb6717de1"},{"href":"https://people.eecs.berkeley.edu/~jordan/sail/readings/andrieu-thoms.pdf"}],"documentFingerprint":"75390582e763e25801cf854bb6717de1"},"uri":"https://people.eecs.berkeley.edu/~jordan/sail/readings/andrieu-thoms.pdf","target":[{"source":"https://people.eecs.berkeley.edu/~jordan/sail/readings/andrieu-thoms.pdf","selector":[{"type":"TextPositionSelector","start":24619,"end":24781},{"type":"TextQuoteSelector","exact":"With the nota-tion introduced in the previous section, we are interested inthe behaviour of the difference| ˇE∗(f (Xi )) − Eπ (f (X))|as i → ∞ for any f : X → R. ","prefix":"hich are discussed in the text. ","suffix":"Although general functionscan be"}]}]}
>```
>%%
>*%%PREFIX%%hich are discussed in the text.%%HIGHLIGHT%% ==With the nota-tion introduced in the previous section, we are interested inthe behaviour of the difference| ˇE∗(f (Xi )) − Eπ (f (X))|as i → ∞ for any f : X → R.== %%POSTFIX%%Although general functionscan be*
>%%LINK%%[[#^zx78aburppc|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^zx78aburppc


>%%
>```annotation-json
>{"created":"2023-06-12T12:20:17.013Z","updated":"2023-06-12T12:20:17.013Z","document":{"title":"","link":[{"href":"urn:x-pdf:75390582e763e25801cf854bb6717de1"},{"href":"https://people.eecs.berkeley.edu/~jordan/sail/readings/andrieu-thoms.pdf"}],"documentFingerprint":"75390582e763e25801cf854bb6717de1"},"uri":"https://people.eecs.berkeley.edu/~jordan/sail/readings/andrieu-thoms.pdf","target":[{"source":"https://people.eecs.berkeley.edu/~jordan/sail/readings/andrieu-thoms.pdf","selector":[{"type":"TextPositionSelector","start":24909,"end":24970},{"type":"TextQuoteSelector","exact":"we willhere assume for simplicity of exposition that |f | ≤ 1","prefix":"6) and (AtchadØ and Fort 2008), ","suffix":". Thestudy of this term is carri"}]}]}
>```
>%%
>*%%PREFIX%%6) and (AtchadØ and Fort 2008),%%HIGHLIGHT%% ==we willhere assume for simplicity of exposition that |f | ≤ 1== %%POSTFIX%%. Thestudy of this term is carri*
>%%LINK%%[[#^edbgh0jde2d|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^edbgh0jde2d


>%%
>```annotation-json
>{"created":"2023-06-12T12:22:01.667Z","updated":"2023-06-12T12:22:01.667Z","document":{"title":"","link":[{"href":"urn:x-pdf:75390582e763e25801cf854bb6717de1"},{"href":"https://people.eecs.berkeley.edu/~jordan/sail/readings/andrieu-thoms.pdf"}],"documentFingerprint":"75390582e763e25801cf854bb6717de1"},"uri":"https://people.eecs.berkeley.edu/~jordan/sail/readings/andrieu-thoms.pdf","target":[{"source":"https://people.eecs.berkeley.edu/~jordan/sail/readings/andrieu-thoms.pdf","selector":[{"type":"TextPositionSelector","start":25273,"end":25574},{"type":"TextQuoteSelector","exact":"P k [f ](x) = P k f (x)  for any f : X → Rnf andx ∈ X defined recursively as P 0f (x) = f (x) , Pf (x) := ∫XP (x, dy)f (y) and P k+1f (x)  = P [P k f ](x) for k ≥ 1. Inthe finite discrete case this corresponds to considering pow-ers P k of the transition matrix P and right multiplying witha vector f ","prefix":" the following standardnotation ","suffix":".) Denoting P i−kiθkif (X ki ) t"}]}]}
>```
>%%
>*%%PREFIX%%the following standardnotation%%HIGHLIGHT%% ==P k [f ](x) = P k f (x)  for any f : X → Rnf andx ∈ X defined recursively as P 0f (x) = f (x) , Pf (x) := ∫XP (x, dy)f (y) and P k+1f (x)  = P [P k f ](x) for k ≥ 1. Inthe finite discrete case this corresponds to considering pow-ers P k of the transition matrix P and right multiplying witha vector f== %%POSTFIX%%.) Denoting P i−kiθkif (X ki ) t*
>%%LINK%%[[#^aml8lv3clil|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^aml8lv3clil


>%%
>```annotation-json
>{"created":"2023-06-12T12:23:44.109Z","updated":"2023-06-12T12:23:44.109Z","document":{"title":"","link":[{"href":"urn:x-pdf:75390582e763e25801cf854bb6717de1"},{"href":"https://people.eecs.berkeley.edu/~jordan/sail/readings/andrieu-thoms.pdf"}],"documentFingerprint":"75390582e763e25801cf854bb6717de1"},"uri":"https://people.eecs.berkeley.edu/~jordan/sail/readings/andrieu-thoms.pdf","target":[{"source":"https://people.eecs.berkeley.edu/~jordan/sail/readings/andrieu-thoms.pdf","selector":[{"type":"TextPositionSelector","start":27258,"end":27273},{"type":"TextQuoteSelector","exact":"chicken and egg","prefix":"a fundamentaldifficulty of the “","suffix":"” type in the study of thestabil"}]}]}
>```
>%%
>*%%PREFIX%%a fundamentaldifficulty of the “%%HIGHLIGHT%% ==chicken and egg== %%POSTFIX%%” type in the study of thestabil*
>%%LINK%%[[#^w41zsokiwp|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^w41zsokiwp


>%%
>```annotation-json
>{"created":"2023-06-12T12:24:37.484Z","updated":"2023-06-12T12:24:37.484Z","document":{"title":"","link":[{"href":"urn:x-pdf:75390582e763e25801cf854bb6717de1"},{"href":"https://people.eecs.berkeley.edu/~jordan/sail/readings/andrieu-thoms.pdf"}],"documentFingerprint":"75390582e763e25801cf854bb6717de1"},"uri":"https://people.eecs.berkeley.edu/~jordan/sail/readings/andrieu-thoms.pdf","target":[{"source":"https://people.eecs.berkeley.edu/~jordan/sail/readings/andrieu-thoms.pdf","selector":[{"type":"TextPositionSelector","start":27358,"end":27560},{"type":"TextQuoteSelector","exact":"Indeed in order to ensure ergodicity, {θi } should stay awayfrom poor values of the parameter θ ∈ \u0005, but proving thestability of {θi } might often require establishing the ergod-icity of the chain {Xi }","prefix":", which is sometimes overlooked.","suffix":"; see Andrieu and Moulines (2006"}]}]}
>```
>%%
>*%%PREFIX%%, which is sometimes overlooked.%%HIGHLIGHT%% ==Indeed in order to ensure ergodicity, {θi } should stay awayfrom poor values of the parameter θ ∈ , but proving thestability of {θi } might often require establishing the ergod-icity of the chain {Xi }== %%POSTFIX%%; see Andrieu and Moulines (2006*
>%%LINK%%[[#^iyhoukik8m8|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^iyhoukik8m8


>%%
>```annotation-json
>{"created":"2023-06-12T12:28:10.931Z","text":"2nd term = \"comparison\", i.e. between $f(X_i)$ (as if the MC has finished being tuned and we want to use the sample at time $i$, i.e. $X_i$) and $P_{\\theta_{k_i}}^{i-k_i} f(X_{k_i})$ (the sample produced at time $k_i$ when the controlled MC has stopped its tuning).\n\nThe first term is a \"remainder\" in the sense that it represents the difference between the first \"tuned\" MC sample (at time $k_i$) and the true desired distribution \n$\\pi$.","updated":"2023-06-12T12:28:10.931Z","document":{"title":"","link":[{"href":"urn:x-pdf:75390582e763e25801cf854bb6717de1"},{"href":"https://people.eecs.berkeley.edu/~jordan/sail/readings/andrieu-thoms.pdf"}],"documentFingerprint":"75390582e763e25801cf854bb6717de1"},"uri":"https://people.eecs.berkeley.edu/~jordan/sail/readings/andrieu-thoms.pdf","target":[{"source":"https://people.eecs.berkeley.edu/~jordan/sail/readings/andrieu-thoms.pdf","selector":[{"type":"TextPositionSelector","start":25953,"end":26058},{"type":"TextQuoteSelector","exact":"the second term corresponds to the aforementionedcomparison and the first term is a simple remainder term","prefix":"− P i−kiθkif (X ki )), (6)where ","suffix":".Perhaps not surprisingly the co"}]}]}
>```
>%%
>*%%PREFIX%%− P i−kiθkif (X ki )), (6)where%%HIGHLIGHT%% ==the second term corresponds to the aforementionedcomparison and the first term is a simple remainder term== %%POSTFIX%%.Perhaps not surprisingly the co*
>%%LINK%%[[#^unspdzgih58|show annotation]]
>%%COMMENT%%
>2nd term = "comparison", i.e. between $f(X_i)$ (as if the MC has finished being tuned and we want to use the sample at time $i$, i.e. $X_i$) and $P_{\theta_{k_i}}^{i-k_i} f(X_{k_i})$ (the sample produced at time $k_i$ when the controlled MC has stopped its tuning).
>
>The first term is a "remainder" in the sense that it represents the difference between the first "tuned" MC sample (at time $k_i$) and the true desired distribution 
>$\pi$.
>%%TAGS%%
>
^unspdzgih58


>%%
>```annotation-json
>{"created":"2023-06-12T12:35:24.998Z","text":"makes sense - the controlled process will end up on a param $\\theta$ at time $k_i$ and we require that the process that continues with $\\theta$ is ergodic.","updated":"2023-06-12T12:35:24.998Z","document":{"title":"","link":[{"href":"urn:x-pdf:75390582e763e25801cf854bb6717de1"},{"href":"https://people.eecs.berkeley.edu/~jordan/sail/readings/andrieu-thoms.pdf"}],"documentFingerprint":"75390582e763e25801cf854bb6717de1"},"uri":"https://people.eecs.berkeley.edu/~jordan/sail/readings/andrieu-thoms.pdf","target":[{"source":"https://people.eecs.berkeley.edu/~jordan/sail/readings/andrieu-thoms.pdf","selector":[{"type":"TextPositionSelector","start":26084,"end":26323},{"type":"TextQuoteSelector","exact":"the convergence to zero of thefirst term, provided that i − ki → ∞  as i → ∞ , dependson the ergodicity of the non-adaptive MCMC chain withfixed parameter θ ∈ \u0005, i.e. requires at least that for anyθ, x ∈ \u0005×X, limk→∞ |P kθ f (x) −π(f )| = 0","prefix":"r term.Perhaps not surprisingly ","suffix":". However sinceboth θki and Xki "}]}]}
>```
>%%
>*%%PREFIX%%r term.Perhaps not surprisingly%%HIGHLIGHT%% ==the convergence to zero of thefirst term, provided that i − ki → ∞  as i → ∞ , dependson the ergodicity of the non-adaptive MCMC chain withfixed parameter θ ∈ , i.e. requires at least that for anyθ, x ∈ ×X, limk→∞ |P kθ f (x) −π(f )| = 0== %%POSTFIX%%. However sinceboth θki and Xki*
>%%LINK%%[[#^0o8sewi4qct|show annotation]]
>%%COMMENT%%
>makes sense - the controlled process will end up on a param $\theta$ at time $k_i$ and we require that the process that continues with $\theta$ is ergodic.
>%%TAGS%%
>
^0o8sewi4qct


>%%
>```annotation-json
>{"created":"2023-06-12T12:42:04.296Z","text":"**Telescoping**\n\nIn this summand the first term is (a), the expectation of a process where $\\theta$ is frozen at time $j+1$ (hence the $P^{i - (j+1)}_{\\theta_{k_i}}$); and (b), the expectation of a process where $\\theta$ is frozen at time $j$.\n\nUsing the telescoping nature to expand this out to give $2 \\times ((i-1) - k_i)$ terms we are only left with the second:\n\n$$ - \\v{\\mathbb{E}}_*(P_{\\theta_{k_i}}^{i-{k_i}} f(X_{k_i})),$$\n\nand the second-to-last:\n$$ \\v{\\mathbb{E}}_*(P_{\\theta_{k_i}}^{i-(i-1)-1} f(X_{(i-1) + 1})) =  \\v{\\mathbb{E}}_*(P_{\\theta_{k_i}}^{0} f(X_{i})) =  \\v{\\mathbb{E}}_*(f(X_{i}))$$\n\ni.e. the expectations of two processes, one which tunes for $k_i$ steps before stopping, and one which tunes for $i-1$ steps (i.e. doesn't really stop tuning---recall that we are looking at $f$ applied to the $i$th sample).\n\n(One annoying bit of notation here: although we're acting as if $i \\in \\mathbb{N}$ and $k_i < i$ are fixed, $\\theta_{k_i}$ being used in subscript of $P$ is not constant---it is:\n\"the expectation of $f$ after $i − k_i$ iterations of the “frozen” time homogeneous Markov transition probability $P_{\\theta_{k_i}}$ initialised with $X_{k_i}$ at time $k_i$ and conditional upon $θ_0, X_0, X_1, \\ldots , X_{k_i}$.\")","updated":"2023-06-12T12:42:04.296Z","document":{"title":"","link":[{"href":"urn:x-pdf:75390582e763e25801cf854bb6717de1"},{"href":"https://people.eecs.berkeley.edu/~jordan/sail/readings/andrieu-thoms.pdf"}],"documentFingerprint":"75390582e763e25801cf854bb6717de1"},"uri":"https://people.eecs.berkeley.edu/~jordan/sail/readings/andrieu-thoms.pdf","target":[{"source":"https://people.eecs.berkeley.edu/~jordan/sail/readings/andrieu-thoms.pdf","selector":[{"type":"TextPositionSelector","start":28311,"end":28410},{"type":"TextQuoteSelector","exact":"E∗ (f (X i )) − ˇE∗(P i−kiθkif (X ki ))=i−1∑j =kiˇE∗(P i−j −1θkif (X j +1))− ˇE∗(P i−jθkif (X j )),","prefix":"g the following telescoping sumˇ","suffix":"which can be easily understood a"}]}]}
>```
>%%
>*%%PREFIX%%g the following telescoping sumˇ%%HIGHLIGHT%% ==E∗ (f (X i )) − ˇE∗(P i−kiθkif (X ki ))=i−1∑j =kiˇE∗(P i−j −1θkif (X j +1))− ˇE∗(P i−jθkif (X j )),== %%POSTFIX%%which can be easily understood a*
>%%LINK%%[[#^lzabp3a1kna|show annotation]]
>%%COMMENT%%
>**Telescoping**
>
>In this summand the first term is (a), the expectation of a process where $\theta$ is frozen at time $j+1$ (hence the $P^{i - (j+1)}_{\theta_{k_i}}$); and (b), the expectation of a process where $\theta$ is frozen at time $j$.
>
>Using the telescoping nature to expand this out to give $2 \times ((i-1) - k_i)$ terms we are only left with the second:
>
>$$ - \v{\mathbb{E}}_*(P_{\theta_{k_i}}^{i-{k_i}} f(X_{k_i})),$$
>
>and the second-to-last:
>$$ \v{\mathbb{E}}_*(P_{\theta_{k_i}}^{i-(i-1)-1} f(X_{(i-1) + 1})) =  \v{\mathbb{E}}_*(P_{\theta_{k_i}}^{0} f(X_{i})) =  \v{\mathbb{E}}_*(f(X_{i}))$$
>
>i.e. the expectations of two processes, one which tunes for $k_i$ steps before stopping, and one which tunes for $i-1$ steps (i.e. doesn't really stop tuning---recall that we are looking at $f$ applied to the $i$th sample).
>
>(One annoying bit of notation here: although we're acting as if $i \in \mathbb{N}$ and $k_i < i$ are fixed, $\theta_{k_i}$ being used in subscript of $P$ is not constant---it is:
>"the expectation of $f$ after $i − k_i$ iterations of the “frozen” time homogeneous Markov transition probability $P_{\theta_{k_i}}$ initialised with $X_{k_i}$ at time $k_i$ and conditional upon $θ_0, X_0, X_1, \ldots , X_{k_i}$.")
>%%TAGS%%
>
^lzabp3a1kna


>%%
>```annotation-json
>{"created":"2023-06-12T13:38:55.021Z","updated":"2023-06-12T13:38:55.021Z","document":{"title":"","link":[{"href":"urn:x-pdf:75390582e763e25801cf854bb6717de1"},{"href":"https://people.eecs.berkeley.edu/~jordan/sail/readings/andrieu-thoms.pdf"}],"documentFingerprint":"75390582e763e25801cf854bb6717de1"},"uri":"https://people.eecs.berkeley.edu/~jordan/sail/readings/andrieu-thoms.pdf","target":[{"source":"https://people.eecs.berkeley.edu/~jordan/sail/readings/andrieu-thoms.pdf","selector":[{"type":"TextPositionSelector","start":28827,"end":28955},{"type":"TextQuoteSelector","exact":"Hence the two terms involved only differ in that attime j the first term updates the chain with θj while thesecond term uses θki","prefix":"rm, albeit between time jand i. ","suffix":" , which can be concisely expres"}]}]}
>```
>%%
>*%%PREFIX%%rm, albeit between time jand i.%%HIGHLIGHT%% ==Hence the two terms involved only differ in that attime j the first term updates the chain with θj while thesecond term uses θki== %%POSTFIX%%, which can be concisely expres*
>%%LINK%%[[#^9zhoh819tdm|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^9zhoh819tdm


>%%
>```annotation-json
>{"created":"2023-06-12T13:40:14.910Z","updated":"2023-06-12T13:40:14.910Z","document":{"title":"","link":[{"href":"urn:x-pdf:75390582e763e25801cf854bb6717de1"},{"href":"https://people.eecs.berkeley.edu/~jordan/sail/readings/andrieu-thoms.pdf"}],"documentFingerprint":"75390582e763e25801cf854bb6717de1"},"uri":"https://people.eecs.berkeley.edu/~jordan/sail/readings/andrieu-thoms.pdf","target":[{"source":"https://people.eecs.berkeley.edu/~jordan/sail/readings/andrieu-thoms.pdf","selector":[{"type":"TextPositionSelector","start":29244,"end":29599},{"type":"TextQuoteSelector","exact":"The role of vanishing adaptation should now be appar-ent. Provided that the transition probability Pθ is suffi-ciently smooth in θ and that the variations of {θi } vanishas i → +∞ (in some unspecified sense at this point) thenwe might expecti−1∑j =kiˇE∗((Pθj − Pθki)P i−j −1θkif (X j ))to vanish if the number of terms in this sum does notgrow too rapidly","prefix":"Pθj − Pθki)P i−j −1θkif (X j )).","suffix":". However as noticed when analys"}]}]}
>```
>%%
>*%%PREFIX%%Pθj − Pθki)P i−j −1θkif (X j )).%%HIGHLIGHT%% ==The role of vanishing adaptation should now be appar-ent. Provided that the transition probability Pθ is suffi-ciently smooth in θ and that the variations of {θi } vanishas i → +∞ (in some unspecified sense at this point) thenwe might expecti−1∑j =kiˇE∗((Pθj − Pθki)P i−j −1θkif (X j ))to vanish if the number of terms in this sum does notgrow too rapidly== %%POSTFIX%%. However as noticed when analys*
>%%LINK%%[[#^0tgjc1hrti|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^0tgjc1hrti


>%%
>```annotation-json
>{"created":"2023-06-12T13:45:42.992Z","updated":"2023-06-12T13:45:42.992Z","document":{"title":"","link":[{"href":"urn:x-pdf:75390582e763e25801cf854bb6717de1"},{"href":"https://people.eecs.berkeley.edu/~jordan/sail/readings/andrieu-thoms.pdf"}],"documentFingerprint":"75390582e763e25801cf854bb6717de1"},"uri":"https://people.eecs.berkeley.edu/~jordan/sail/readings/andrieu-thoms.pdf","target":[{"source":"https://people.eecs.berkeley.edu/~jordan/sail/readings/andrieu-thoms.pdf","selector":[{"type":"TextPositionSelector","start":31196,"end":31370},{"type":"TextQuoteSelector","exact":"points to the pri-mary conditions under which one might expect controlledMCMC algorithms to be π -ergodic: “expected ergodicityand continuity of the transition probabilities”","prefix":"hand, using basic arguments, it ","suffix":". On the otherhand it also point"}]}]}
>```
>%%
>*%%PREFIX%%hand, using basic arguments, it%%HIGHLIGHT%% ==points to the pri-mary conditions under which one might expect controlledMCMC algorithms to be π -ergodic: “expected ergodicityand continuity of the transition probabilities”== %%POSTFIX%%. On the otherhand it also point*
>%%LINK%%[[#^pye8fqcnlhs|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^pye8fqcnlhs


>%%
>```annotation-json
>{"created":"2023-06-12T13:46:00.127Z","updated":"2023-06-12T13:46:00.127Z","document":{"title":"","link":[{"href":"urn:x-pdf:75390582e763e25801cf854bb6717de1"},{"href":"https://people.eecs.berkeley.edu/~jordan/sail/readings/andrieu-thoms.pdf"}],"documentFingerprint":"75390582e763e25801cf854bb6717de1"},"uri":"https://people.eecs.berkeley.edu/~jordan/sail/readings/andrieu-thoms.pdf","target":[{"source":"https://people.eecs.berkeley.edu/~jordan/sail/readings/andrieu-thoms.pdf","selector":[{"type":"TextPositionSelector","start":31525,"end":31691},{"type":"TextQuoteSelector","exact":"The problem stems from the fact that it isrequired to prove that the algorithm is not unlucky enoughto tune θ to poor values, leading to possibly unstable algo-rithms","prefix":"mary condi-tions are satisfied. ","suffix":". The uniform conditions suggest"}]}]}
>```
>%%
>*%%PREFIX%%mary condi-tions are satisfied.%%HIGHLIGHT%% ==The problem stems from the fact that it isrequired to prove that the algorithm is not unlucky enoughto tune θ to poor values, leading to possibly unstable algo-rithms== %%POSTFIX%%. The uniform conditions suggest*
>%%LINK%%[[#^iqd7l2qvrvd|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^iqd7l2qvrvd


>%%
>```annotation-json
>{"created":"2023-06-12T13:56:25.446Z","text":"c.f. Eq. (7)","updated":"2023-06-12T13:56:25.446Z","document":{"title":"","link":[{"href":"urn:x-pdf:75390582e763e25801cf854bb6717de1"},{"href":"https://people.eecs.berkeley.edu/~jordan/sail/readings/andrieu-thoms.pdf"}],"documentFingerprint":"75390582e763e25801cf854bb6717de1"},"uri":"https://people.eecs.berkeley.edu/~jordan/sail/readings/andrieu-thoms.pdf","target":[{"source":"https://people.eecs.berkeley.edu/~jordan/sail/readings/andrieu-thoms.pdf","selector":[{"type":"TextPositionSelector","start":31977,"end":31992},{"type":"TextQuoteSelector","exact":"such uniformity","prefix":"ever it is of-ten the case that ","suffix":" holds for subsets K ⊂ \u0005.For exa"}]}]}
>```
>%%
>*%%PREFIX%%ever it is of-ten the case that%%HIGHLIGHT%% ==such uniformity== %%POSTFIX%%holds for subsets K ⊂ .For exa*
>%%LINK%%[[#^3azrz0moy9l|show annotation]]
>%%COMMENT%%
>c.f. Eq. (7)
>%%TAGS%%
>
^3azrz0moy9l


>%%
>```annotation-json
>{"created":"2023-06-12T13:58:57.733Z","updated":"2023-06-12T13:58:57.733Z","document":{"title":"","link":[{"href":"urn:x-pdf:75390582e763e25801cf854bb6717de1"},{"href":"https://people.eecs.berkeley.edu/~jordan/sail/readings/andrieu-thoms.pdf"}],"documentFingerprint":"75390582e763e25801cf854bb6717de1"},"uri":"https://people.eecs.berkeley.edu/~jordan/sail/readings/andrieu-thoms.pdf","target":[{"source":"https://people.eecs.berkeley.edu/~jordan/sail/readings/andrieu-thoms.pdf","selector":[{"type":"TextPositionSelector","start":32648,"end":33151},{"type":"TextQuoteSelector","exact":"A general approach for adaptive trun-cation is developed and analysed in Andrieu et al. (2005)and Andrieu and Moulines (2006). It takes advantage of thefact that uniform ergodicity and continuity can be shown forfamilies of subsets of {K i ⊂ \u0005}, such that {K i ⊂ \u0005} is acovering of \u0005 such that K i ⊂ K i+1 for i ≥ 0. The strategythen consists of adapting the truncation of the algorithm onthe fly in order to ensure that {θi } does not wander too fasttowards inappropriate values in \u0005 or at its boundary","prefix":"h “fixed”truncation strategies. ","suffix":", henceensuring that ergodicity "}]}]}
>```
>%%
>*%%PREFIX%%h “fixed”truncation strategies.%%HIGHLIGHT%% ==A general approach for adaptive trun-cation is developed and analysed in Andrieu et al. (2005)and Andrieu and Moulines (2006). It takes advantage of thefact that uniform ergodicity and continuity can be shown forfamilies of subsets of {K i ⊂ }, such that {K i ⊂ } is acovering of  such that K i ⊂ K i+1 for i ≥ 0. The strategythen consists of adapting the truncation of the algorithm onthe fly in order to ensure that {θi } does not wander too fasttowards inappropriate values in  or at its boundary== %%POSTFIX%%, henceensuring that ergodicity*
>%%LINK%%[[#^711eb1a3jp8|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^711eb1a3jp8


>%%
>```annotation-json
>{"created":"2023-06-12T14:00:17.344Z","updated":"2023-06-12T14:00:17.344Z","document":{"title":"","link":[{"href":"urn:x-pdf:75390582e763e25801cf854bb6717de1"},{"href":"https://people.eecs.berkeley.edu/~jordan/sail/readings/andrieu-thoms.pdf"}],"documentFingerprint":"75390582e763e25801cf854bb6717de1"},"uri":"https://people.eecs.berkeley.edu/~jordan/sail/readings/andrieu-thoms.pdf","target":[{"source":"https://people.eecs.berkeley.edu/~jordan/sail/readings/andrieu-thoms.pdf","selector":[{"type":"TextPositionSelector","start":33763,"end":34005},{"type":"TextQuoteSelector","exact":"While this approach is general and comes with ageneral and applicable theory, it might be computationallywasteful in some situations and more crucially does not re-flect the fact that numerous algorithm naturally present sta-bility properties","prefix":"ails decay superexpo-nentially. ","suffix":". Another possibility consists o"}]}]}
>```
>%%
>*%%PREFIX%%ails decay superexpo-nentially.%%HIGHLIGHT%% ==While this approach is general and comes with ageneral and applicable theory, it might be computationallywasteful in some situations and more crucially does not re-flect the fact that numerous algorithm naturally present sta-bility properties== %%POSTFIX%%. Another possibility consists o*
>%%LINK%%[[#^hj1py7hdlww|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^hj1py7hdlww


>%%
>```annotation-json
>{"created":"2023-06-12T15:02:32.900Z","updated":"2023-06-12T15:02:32.900Z","document":{"title":"","link":[{"href":"urn:x-pdf:75390582e763e25801cf854bb6717de1"},{"href":"https://people.eecs.berkeley.edu/~jordan/sail/readings/andrieu-thoms.pdf"}],"documentFingerprint":"75390582e763e25801cf854bb6717de1"},"uri":"https://people.eecs.berkeley.edu/~jordan/sail/readings/andrieu-thoms.pdf","target":[{"source":"https://people.eecs.berkeley.edu/~jordan/sail/readings/andrieu-thoms.pdf","selector":[{"type":"TextPositionSelector","start":37448,"end":37563},{"type":"TextQuoteSelector","exact":"The first term corresponds to the Monte Carlo fluctuationswhile the second term is the price to pay for adaptation.","prefix":"at Comput (2008) 18: 343–373 351","suffix":" As-suming that γi = i−α for α ∈"}]}]}
>```
>%%
>*%%PREFIX%%at Comput (2008) 18: 343–373 351%%HIGHLIGHT%% ==The first term corresponds to the Monte Carlo fluctuationswhile the second term is the price to pay for adaptation.== %%POSTFIX%%As-suming that γi = i−α for α ∈*
>%%LINK%%[[#^80ssc0ztyr|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^80ssc0ztyr
